<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
<title>CowTalk</title>
<link>http://www.cowtowncoder.com/blog/blog.html</link>
<description>Moo-able Type for Cowtowncoder.com</description>
<language>en-US</language>
<copyright>Copyright 2013</copyright>
<lastBuildDate>Tue, 13 Aug 2013 23:18:05 -0700</lastBuildDate>
<pubDate>Tue, 13 Aug 2013 23:18:05 -0700</pubDate>
<generator>http://thingamablog.sf.net</generator>
<docs>http://en.wikipedia.org/wiki/Rss</docs>

<item>
<title>On Jackson 2.2</title>
<description>&lt;p&gt;
      Here's another thing I need to write about, from my &amp;quot;todo bloklog&amp;quot; (blog 
      backlog): overview of Jackson 2.2 release.&lt;br&gt;As usual, &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease22&quot;&gt;official 
      2.2 release notes&lt;/a&gt; are worth checking out for more detailed listing.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Overview&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Jackson 2.2.0 was released in April, 2013 -- that is, four months ago -- 
      and the latest patch version currently available is 2.2.2. It has proven 
      a nice, stable release, and is currently used by frameworks such as &lt;a href=&quot;https://github.com/codahale/dropwizard&quot;&gt;DropWizard&lt;/a&gt; 
      (my current favorite Java service platform). This is also the current 
      stable version, as the development for 2.3 is not yet complete.
    &lt;/p&gt;
    &lt;p&gt;
      As opposed to earlier releases (2.0 major, 2.1 minor) which overflowed 
      with new functionality, focus with 2.2 was to really stabilize 
      functionality and close as many open bugs as possible; especially ones 
      related to new 2.x functionality.&lt;br&gt;Related to this, we wanted to 
      improve parity (coverage of features to different parts; that is, that 
      both serialization and deserialization support things; that 
      Map/Node/POJO handling would be as similar as possible).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Enhancements to serializer, deserializer processing&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One problem area, with respect to writing custom handlers for structured 
      non-POJO types (esp. container types: arrays, Collections, Maps), was 
      that &lt;i&gt;BeanSerializerModifier&lt;/i&gt; and &lt;i&gt;BeanDeserializerModifier&lt;/i&gt; 
      handlers could only be used for POJO types.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      But custom handling is needed for container types too; and especially so 
      when adding support for third-party libraries like Trove, Guava and 
      HPPC. 2.2 extended these interfaces to allow post-processing 
      serializers/deserializers for all types (also including scalar types).
    &lt;/p&gt;
    &lt;p&gt;
      Ability to post-process (de)serializers of all types should reduce the 
      need for writing custom (de)serializers from scratch: it is possible -- 
      for example -- to take the default (de)serializer, and use 
      post-processor to create (de)serializer that delegates to the standard 
      version for certain cases, or for certain part of processing.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Converters &lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The biggest new feature was adding annotation-based support for adding 
      things called &amp;quot;Converters&amp;quot;. It can be seen as sort of further extension 
      for the idea that one should be able to refine handling with small(er) 
      component, instead of having to write custom handlers from scratch.
    &lt;/p&gt;
    &lt;p&gt;
      The basic idea is simple: to serialize custom types (that Jackson would 
      not know how to handle correctly) one can write converters that know how 
      to take a custom type and convert it into an intermediate object that 
      Jackson already knows how to serialize. This intermediate form could be 
      simple &lt;i&gt;java.util.Map&lt;/i&gt; or &lt;i&gt;JsonNode &lt;/i&gt;(tree model), or even 
      just another more traditional POJO.
    &lt;/p&gt;
    &lt;p&gt;
      And for deserialization, do the reverse: let Jackson deserialize JSON 
      into this intermediate type; and call converter to get to the custom 
      type.
    &lt;/p&gt;
    &lt;p&gt;
      Typically you will write one or two converters (one if you just need 
      converter for either serialization or deserialization; two if both); and 
      then either annotate the type that needs converter(s); or property of 
      that type that needs converter(s):
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;@JsonSerialize(converter=SerializationConverter.class)&lt;br&gt;@JsonDeserialize(converter=DeserializationConverter.class)&lt;br&gt;public class Point {&lt;br&gt;  private int x, y;&lt;br&gt;  public MyPoint(int x, int y) {&lt;br&gt;   this.x = x;&lt;br&gt;   this.y = y;&lt;br&gt;  }&lt;br&gt;  public int x() { return x; }&lt;br&gt;  public int y() { return y; } &lt;br&gt;}&lt;br&gt;&lt;br&gt;class SerializationConverter extends StdConverter&amp;lt;ConvertingBean, int[]&amp;gt; {&lt;br&gt;   public int[] convert(MyPoint p) {&lt;br&gt;     return new int[] { p.x(), p.y() };&lt;br&gt;   }&lt;br&gt;}&lt;br&gt;// similarly for DeserializationConverter: StdConverter is convenient base class&lt;/pre&gt;
    &lt;div&gt;
      &lt;hr&gt;
      
    &lt;/div&gt;
    &lt;div&gt;
      
    &lt;/div&gt;
    &lt;div&gt;
      This feature was inspired by similar concept in JAXB, and should have 
      been included a long time ago (actually, 2.1 already added internal 
      support for converters; 2.2 just added annotation and connected the 
      dots).
    &lt;/div&gt;
    &lt;div&gt;
      
    &lt;/div&gt;
    &lt;div&gt;
      One thing worth noting regarding above is that use of &lt;i&gt;StdConverter&lt;/i&gt; 
      is strongly recommended; although you may directly implement Converter 
      there is usually little need. Also note that although example associated 
      converters directly with the type, you can also add them to property 
      definition; this can be useful when dealing with third-party types 
      (although you can also use mix-in annotations for those cases).
    &lt;/div&gt;
    &lt;p&gt;
      &lt;b&gt;4. Android&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One &amp;quot;unusual&amp;quot; area for improvements was work to try to make Jackson run 
      better on Android platform. Android has its set of quirks; and although 
      Jackson was already working well from functionality perspective, there 
      were obvious performance problems. This was especially true for 
      data-binding, where initial startup overhead has been problematic.
    &lt;/p&gt;
    &lt;p&gt;
      One simple improvement was elimination of file VERSION.txt. While it 
      seemed harmless enough thing for J2SE, Android's package loader has 
      surprising overhead when loading resources from within a jar -- at least 
      on some versions, contents of jar are retained in memory basically 
      DOUBLING amount of memory needed. 2.2 replaced text-file based version 
      discovery with simple class generation (as part of build, that is, 
      static source generation).
    &lt;/p&gt;
    &lt;p&gt;
      Version 2.2 also contained significant amount of internal refactorings, 
      to try to reduce startup overhead, by both simplifying set up of 
      (de)serializers, and to try to improve lazy-loading aspects.&lt;br&gt;One 
      challenge, however, is that we still do not have a good set of 
      benchmarks to actually verify effects of these changes. So while the 
      intent was to improve startup performance, we do not have solid numbers 
      to report, yet.
    &lt;/p&gt;
    &lt;p&gt;
      On plus side, there is some on-going work to do more performance 
      measurements; and I hope to write more about these efforts once related 
      work is made public (it is not yet; I am not driving these efforts, but 
      have helped).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. JAX-RS: additional caching&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Another area of performance improvements was that of JAX-RS provider. 
      Earlier versions did reuse internal `ObjectMapper`, but had to do more 
      per-call annotation processing. 2.2 added simple caching of results of 
      annotation introspection, and should help reduce overhead.
    &lt;/p&gt;
    &lt;p&gt;
      One other important change was structural: before 2.2, there were 
      multiple separate github projects (three; one for JSON, another for 
      Smile, third for XML). With 2.2 we now have a single Github project, &lt;a href=&quot;https://github.com/FasterXML/jackson-jaxrs-providers&quot;&gt;jackson-jaxrs-providers&lt;/a&gt;, 
      with multiple Maven sub-projects that share code via a base package. 
      This should simplify development, and reduce likelihood of getting cut'n 
      paste errors.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. AfterBurner becomes Production Ready&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One more big milestone concerned &lt;a href=&quot;https://github.com/FasterXML/jackson-module-afterburner&quot;&gt;Afterburner&lt;/a&gt; 
      module (what is it? Check out &lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2012/04/entry_470.html&quot;&gt;this 
      earlier entry&lt;/a&gt;). With a little help from my friends (special thanks 
      to Steven Schlansker for his significant contributions!), all known 
      issues were addressed and new checks added, such that we can now 
      consider Afterburner production ready.
    &lt;/p&gt;
    &lt;p&gt;
      Given that use of Afterburner can give you 30-50% boost in throughput, 
      when using data-binding, it might be good time to check it out.
    &lt;/p&gt;
    &lt;p&gt;
      
    &lt;/p&gt;
    &lt;p&gt;
      
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#480</link>
<guid>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#480</guid>

<category>Java</category>

<category>JSON</category>

<category>Open Source</category>

<pubDate>Tue, 13 Aug 2013 22:37:15 -0700</pubDate>
</item>

<item>
<title>Brief History of Jackson the JSON processor</title>
<description>&lt;p&gt;
      (Disclaimer: this article talks about &lt;a href=&quot;https://github.com/FasterXML/jackson&quot;&gt;Jackson 
      JSON processor&lt;/a&gt; -- not other Jacksons, like American cities or 
      presidents -- those others can be found from Wikipedia)
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;0. Background&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      It occurred to me that although it is almost six years since I released 
      the first public version of Jackson, I have not actually written much 
      about events surrounding Jackson development -- I have written about its 
      features, usage, and other important things. But not that much about how 
      it came about.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Since still remember fairly well how things worked out, and have 
      secondary archives (like this blog, Maven/SVN/Github repositories) 
      available for fact-checking the timeline, it seems like high time to 
      write a short(ish) historical document on the most popular OSS project I 
      have authored.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Beginning: first there was Streaming&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Sometime in early 2007, I was working at Amazon.com, and had 
      successfully used XML as the underying data format for couple of web 
      services. This was partly due to having written &lt;a href=&quot;http://wiki.fasterxml.com/WoodstoxHome&quot;&gt;Woodstox&lt;/a&gt;, 
      a high-performance Java XML parser. I was actually relatively content 
      with the way things worked with XML, and had learnt to appreciate 
      benefits of open, standard, text-based data format (including 
      developer-debuggability, interoperability and -- when done properly -- 
      even simplicity).&lt;br&gt;But I had also been bitten a few times by XML 
      data-binding solutions like JAXB; and was frustrated both by 
      complexities of some tools, and by direction that XML-centric developers 
      were taking, focusing unnecessarily in the format (XML) itself, instead 
      of how to solve actual development problems.
    &lt;/p&gt;
    &lt;p&gt;
      So when I happened to read about JSON data format, I immediately saw 
      potential benefits: the main one being that since it was a &lt;b&gt;Data Format&lt;/b&gt; 
      -- and not a (Textual) &lt;b&gt;Markup Format&lt;/b&gt; (like XML) -- it should be 
      much easier to convert between JSON and (Java) objects. And if that was 
      simpler, perhaps tools could actually do more; offer more intuitive and 
      powerful functionality, instead of fighting with complex monsters like 
      XML Schema or (heaven forbid) lead devs to XSLT.&lt;br&gt;Other features of 
      JSON that were claimed as benefits, like slightly more compact size 
      (marginally so), or better readabilty (subjective) I didn't really 
      consider particularly impresive.&lt;br&gt;Beyond appreciating good fit of JSON 
      for web service use case, I figured that writing a simple streaming 
      tokenizer and generator should be easy: after all, I had spent lots of 
      time writing low-level components necessary for tokenizing content (I 
      started writing Woodstox in late 2003, around time Stax API was 
      finalized)
    &lt;/p&gt;
    &lt;p&gt;
      Turns out I was right: I got a streaming parser working and in about two 
      weeks (and generator in less than a week). In a month I had things 
      working well enough that the library could be used for something. And 
      then it was ready to be released (&amp;quot;release early, release often&amp;quot;); and 
      rest is history, as they say.
    &lt;/p&gt;
    &lt;p&gt;
      Another reason for writing Jackson, which I have occasionally mentioned, 
      was what I saw as a sorry state of JSON tools -- my personal pet peeve 
      was use of org.json's reference implementation. While it was fine as a 
      proof-of-concept, I consider(ed) it a toy library, too simplistic, 
      underpowered thing for &amp;quot;real&amp;quot; work. Other alternatives just seemed to 
      short-change one aspect or another: I was especially surprised to find 
      total lack of modularity (streaming vs higher levels) and scant support 
      for true data-binding -- solutions tended to either assume unusual 
      conventions or require lots of seemingly unnecessary code to be written. 
      If I am to write code, I'd rather do it via efficient streaming 
      interface; or if not, get a powerful and convenient data-binding. Not a 
      half-assed XML-influenced tree model, which was en vogue (and sadly, 
      often still is).
    &lt;/p&gt;
    &lt;p&gt;
      And the last thing regarding ancient history: the name. I actually do 
      not remember story behind it -- obviously it is a play on JSON. And I 
      vaguely recall toying with the idea of calling library &amp;quot;Jason&amp;quot;, but 
      deciding that might sound too creepy (I knew a few Jasons, and didn't 
      want confusion). Compared to Woodstox -- where I actually remember that 
      my friend Kirk P gave the idea (related to Snoopy's friend, bird named 
      Woodstock!) -- I actually don't really know who to give credit to the 
      idea, or inspiration to it.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. With a FAST Streaming library...&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Having written (and quickly published in &lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2007/08/entry_45.html&quot;&gt;August 
      2007&lt;/a&gt;) streaming-only version of Jackson, I spent some time 
      optimizing and measuring things, as well as writing some code to see how 
      convenient library is to use. But my initial thinking was to wrap things 
      up relatively soon, and &amp;quot;let Someone Else write the Important Pieces&amp;quot;. 
      And by &amp;quot;important pieces&amp;quot; I mostly meant a data-binding layer; something 
      like what JAXB and XMLBeans are to XML Streaming components (SAX/Stax).
    &lt;/p&gt;
    &lt;p&gt;
      The main reasons for my hesitation were two-fold: I thought that
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        writing a data-binding library will be lots of work, even if JSON 
        lends itself much more easily to doing that; and
      &lt;/li&gt;
      &lt;li&gt;
        to do binding efficiently, I would have to use code-generation; 
        Reflection API was &amp;quot;known&amp;quot; to be unbearably slow
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      Turns out that I was 50% right: data-binding has consumed vast majority 
      of time I have spent with Jackson. But I was largely wrong with respect 
      to Reflection. But more on that in a bit.
    &lt;/p&gt;
    &lt;p&gt;
      In short term (during summer and autumn of 2008) I did write &amp;quot;simple&amp;quot; 
      data-binding, to bind Java Lists and Maps to/from token streams; and I 
      also wrote a simple Tree Model, latter of which has been rewritten since 
      then.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. ... but No One Built It, So I did&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Jackson the library did get relatively high level of publicity from 
      early on. This was mostly due to my earlier work on Woodstox, and its 
      adoption by all major second-generation Java SOAP stacks (CXF nee XFire; 
      Axis 2). Given my reputation for producing fast parsers, generators, 
      there was interest in using what I had written for JSON. But early 
      adopters used things as is; and no one did (to my knowledge) try to 
      build higher-level abstractions that I eagerly wanted to be written.
    &lt;/p&gt;
    &lt;p&gt;
      But that alone might not have been enough to push me to try my luck 
      writing data-binding. What was needed was a development that made me 
      irritated enough to dive in deep... and sure enough, something did 
      emerge.
    &lt;/p&gt;
    &lt;p&gt;
      So what was the trigger? It was the idea of using XML APIs to process 
      JSON (that is, use adapters to expose JSON content as if it was XML). 
      While most developers who wrote such tools consider this to be a 
      stop-gap solution to ease transition, many developers did not seem to 
      know this.&lt;br&gt;I thought (and still think) that this is an &lt;b&gt;OBVIOUSLY&lt;/b&gt; 
      bad idea; and initially did not spend much time refuting merits of the 
      idea -- why bother, as anyone should see the problem? I assumed that any 
      sane Java developer would obviously see that &amp;quot;Format Impedance&amp;quot; -- 
      difference between JSON's Object (or Frame) structure and XML Hierarchic 
      model -- is a major obstacle, and would render use of JSON even MORE 
      CUMBERSOME than using XML.
    &lt;/p&gt;
    &lt;p&gt;
      And yet I saw people suggesting use of tools like Jettison (JSON via 
      Stax API), even integrating this into otherwise good frameworks (JAX-RS 
      like Jersey). Madness!
    &lt;/p&gt;
    &lt;p&gt;
      Given that developers appeared intent ruining the good thing, I figured 
      I need to show the Better Way; just talking about that would not be 
      enough.&lt;br&gt;So, late in 2008, around time I moved on from Amazon, I 
      started working on a first-class Java/JSON data-binding solution. This 
      can be thought of as &amp;quot;real&amp;quot; start of Jackson as we know it today; bit 
      over one year after the first release.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. Start data-binding by writing Serialization side&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The first Jackson version to contain real data-binding was 0.9.5, 
      released December of 2008. Realizing that this was going to be a big 
      undertaking, I first focused on simpler problem of serializing POJOs as 
      JSON (that is, taking values of Java objects, writing equivalent JSON 
      output).&lt;br&gt;Also, to make it likely that I actually complete the task, I 
      decided to simply use Reflection &amp;quot;at first&amp;quot;; performance should really 
      matter only once thing actually works. Besides, this way I would have 
      some idea as to magnitude of the overhead: having written a fair bit of 
      manual JSON handling code, it would be easy to compare performance of 
      hand-written, and fully automated data-binder.
    &lt;/p&gt;
    &lt;p&gt;
      I think serializer took about a month to work to some degree, and a week 
      or two to weed out bugs. The biggest surprise to me was that Reflection 
      overhead actually was NOT all that big -- it seemed to add maybe 30-40% 
      time; some of which might be due to other overhead beside Reflection 
      access (Reflection is just used for dynamically calling get-methods or 
      accessing field values). This was such a non-issue for the longest time, 
      that it took multiple years for me to go back to the idea of generating 
      accessor code (for curious, &lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2012/04/entry_470.html&quot;&gt;Afterburner 
      Module&lt;/a&gt; is the extension that finally does this).
    &lt;/p&gt;
    &lt;p&gt;
      My decision to start with Serialization (without considering the other 
      direction, deserialization) was good one for the project, I believe, but 
      it did have one longer-term downside: much of the code between two parts 
      was disjoint. Partly this was due to my then view that there are many 
      use cases where only one side is needed -- for example, Java service 
      only every writing JSON output, but not necessarily reading (simple 
      query parameters and URL path go a long way). But big part was that I 
      did not want to slow down writing of serialization by having to also 
      consider challenges in deserialization.&lt;br&gt;And finally, I had some bad 
      memories from JAXB, where requirements to have both getters AND setters 
      was occasionally a pain-in-the-buttocks, for write-only use cases. I did 
      not want to repeat mistakes of others.
    &lt;/p&gt;
    &lt;p&gt;
      Perhaps the biggest practical result of almost complete isolation 
      between serialization and deserialization side was that sometimes 
      annotations needed to be added in multiple places; like indicating both 
      setter and getter what the JSON property name should be. Over time I 
      realized that this was not a good things; but the problem itself was 
      only resolved in Jackson 1.9, much later.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. And wrap it up with Deserialization&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      After serialization (and resulting 0.9.5) release, I continued work with 
      deserialization, and perhaps surprisingly finished it slightly faster 
      than serialization. Or perhaps it is not that surprising; even without 
      working on deserialization concepts earlier, I had nonetheless tackled 
      many of issues I would need to solve, including that of using Reflection 
      efficiently and conveniently; and that of resolving generic types (which 
      is a hideously tricky problem in Java, as readers of my blog should &lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2008/12/entry_126.html&quot;&gt;know 
      by now&lt;/a&gt;).
    &lt;/p&gt;
    &lt;p&gt;
      Result of this was 0.9.6 release in January 2009.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. And then on to Writing Documentation&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      After managing to get the first fully functional version of data-binding 
      available, I realized that the next blocker would be lack of 
      documentation. So far I had blogged occasionally about Jackson usage; 
      but for the most part I had relied on resourcefulness of the early 
      adopters, those hard-working hardy pioneers of development. But if 
      Jackson was to become the King of JSON on Java platform, I would need to 
      do more for it users.
    &lt;/p&gt;
    &lt;p&gt;
      Looking blog at my blog archive I can see that some of the most 
      important and most read articles on the site are from January of 2009. 
      Beyond the obvious introductions to various operating modes (like &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2009/01/entry_137.html&quot;&gt;Method 
      2, Data Binding&lt;/a&gt;&amp;quot;), I am especially proud of &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2009/01/entry_131.html&quot;&gt;There 
      are Three Ways to Process Json!&lt;/a&gt;&amp;quot; -- an article that I think is still 
      relevant. And something I wish every Java JSON developer would read, 
      even if they didn't necessarily agree with all of it. I am surprised how 
      many developers blindly assume that one particular view -- often the 
      Tree Model -- is the only mode in existence.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7. Trailblazing: finally getting to add Advanced Features &lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Up until version 1.0 (&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2009/05/entry_264.html&quot;&gt;released 
      May 2009&lt;/a&gt;), I don't consider my work to be particularly new or 
      innovative: I was using good ideas from past implementations and my 
      experience in building better parsers, generators, tree models and data 
      binders. I felt Jackson was ahead of competition in both XML and JSON 
      space; but perhaps the only truly advanced thing was that of generic 
      type resolution, and even there, I had more to learn yet (eventually I 
      wrote &lt;a href=&quot;https://github.com/cowtowncoder/java-classmate&quot;&gt;Java 
      ClassMate&lt;/a&gt;, which I consider the first Java library to actually get 
      generic type resolution right -- more so than Jackson itself).
    &lt;/p&gt;
    &lt;p&gt;
      This lack of truly new, advanced (from my point of view) features was 
      mostly since there was so much to do, all the foundational code, 
      implementing all basic and intermediate things that were (or should have 
      been) expected from a Java data-binding library. I did have ideas, but 
      in many cases had postponed those until I felt I had time to spare on 
      &amp;quot;nice-to-have&amp;quot; things, or features that were more speculative and might 
      not even work; either functionally, or with respect to developers 
      finding them useful.
    &lt;/p&gt;
    &lt;p&gt;
      So at this point, I figured I would have the luxury of aiming higher; 
      not just making a bit Better Mousetrap, but something that is... 
      Something Else altogether. And with following 1.x versions, I started 
      implementing things that I consider somewhat advanced, pushing the 
      envelope a bit. I could talk or write for hours on various features; 
      what follows is just a sampling. For slightly longer take, read my 
      earlier &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2010/11/entry_434.html&quot;&gt;7 
      Killer Features of Jackson&lt;/a&gt;&amp;quot;.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.1 Support for JAXB annotations&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      With Jackson 1.1, I also started considering interoperability. And 
      although I thought that compatibility with XML is a Bad Idea, when done 
      at API level, I thought that certain aspects could be useful: 
      specifically, ability to use (a subset of) JAXB annotations for 
      customizing data-binding.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Since I did not think that JAXB annotations could suffice alone to cover 
      all configuration needs, I had to figure a way for JAXB and Jackson 
      annotations to co-exist. The result is concept of &amp;quot;Annotation 
      Introspector&amp;quot;, and it is something I am actually proud of: even if 
      supporting JAXB annotations has been lots of work, and caused various 
      frustrations (mostly as JAXB is XML-specific, and some concepts do not 
      translate well), I think the mechanism used for isolating annotation 
      access from rest of the code has worked very well. It is one area that I 
      managed to design right the first time.
    &lt;/p&gt;
    &lt;p&gt;
      It is also worth mentioning that beyond ability to use alternative 
      &amp;quot;annotation sets&amp;quot;, Jackson's annotation handling logic has always been 
      relatively advanced: for example, whereas standard JDK annotation 
      handling does not support overriding (that is; annotations are not 
      &amp;quot;inherited&amp;quot; from overridden methods), Jackson supports inheritance of 
      Class, Method and even Constructor annotations. This has proven like a 
      good decision, even if implementing it for 1.0 was lots of work.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.2 Mix-in annotations&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One of challenges with Java Annotations is the fact that one has to be 
      able to modify classes that are annotated. Beyond requiring actual 
      access to sources, this can also add unnecessary and unwanted 
      dependencies from value classes to annotations; and in case of Jackson, 
      these dependencies are in wrong direction, from design perspective.
    &lt;/p&gt;
    &lt;p&gt;
      But what if one could just loosely associate annotations, instead of 
      having to forcible add them in classes? This was the thought exercise I 
      had; and led to what I think was the first implementation in Java of &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2009/08/entry_305.html&quot;&gt;mix-in 
      annotations&lt;/a&gt;&amp;quot;. I am happy that 4 years since introduction (they were 
      added in &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease12&quot;&gt;Jackson 1.2&lt;/a&gt;), 
      mix-in annotations are one of most loved Jackson features; and something 
      that I still consider innovative.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.3 Polymorphic type support&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One feature that I was hoping to avoid having to implement (kind of 
      similar, in that sense, to data-binding itself) was support for one of 
      core Object Serialization concepts (but not necessarily data-binding 
      concept; data is not polymorphic, classes are): that of type metadata.&lt;br&gt;What 
      I mean here is that given a single static (declared) type, one will 
      still be able to deserialize instances of multiple types. The challenge 
      is that when serializing things there is no problem -- type is available 
      from instance being serialized -- but to deserialize properly, 
      additional information is needed.
    &lt;/p&gt;
    &lt;p&gt;
      There are multiple problems in trying to support this with JSON: 
      starting with obvious problem of JSON not having separation of data and 
      metadata (with XML, for example, it is easy to &amp;quot;hide&amp;quot; metadata as 
      attributes). But beyond this question, there are various alternatives 
      for type identifiers (logical name or physical Java class?), as well as 
      alternative inclusion mechanisms (additional property? What name? Or, 
      use wrapper Array or Object).
    &lt;/p&gt;
    &lt;p&gt;
      I spent lots of time trying to figure out a system that would satisfy 
      all the constraints I put; keep things easy to use, simple, and yet 
      powerful and configurable enough.&lt;br&gt;It took multiple months to figure 
      it all out; but in the end I was satisfied with my design. Polymorphic 
      type handling was included in &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease15&quot;&gt;Jackson 
      1.5&lt;/a&gt;; less than one year after release of 1.0. And still most Java 
      JSON libraries have no support at all for polymorphic types: or at most 
      support fixed use of Java class name -- I know how much work it can be, 
      but at least one could learn from existing implementations (which is 
      more than I had)
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.4 No more monkey code -- Mr Bean can implement your classes&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Of all the advanced features Jackson offers, this is my own personal 
      favorite: and something I had actually hoped to tackle even before 1.0 
      release.
    &lt;/p&gt;
    &lt;p&gt;
      For full description, go ahead and read &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2011/08/entry_459.html&quot;&gt;Mr 
      Bean aka Abstract Type Materialization&lt;/a&gt;&amp;quot;; but the basic idea is, once 
      again, simple: why is it that even if you can define interface of your 
      data type as a simple interface, you still need to write monkey to code 
      around it? Other languages have solutions there; and some later Java 
      Frameworks like Lombok have presented some alternatives. But I am still 
      not aware of a general-purpose Java library for doing what Mr Bean does 
      (NOTE: you CAN actually use Mr Bean outside of Jackson too!).
    &lt;/p&gt;
    &lt;p&gt;
      Mr Bean was included in &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease16&quot;&gt;Jackson 
      1.6&lt;/a&gt; -- which was a release FULL of good, innovative new stuff. The 
      reason it took such a long time for me to build was hesitation -- it is 
      the first time I used Java bytecode generation. But after starting to 
      write code I learnt that it was surprisingly easy to do; and I just 
      wished I had started earlier.&lt;br&gt;Part of simplicity was due to the fact 
      that literally the only thing to generate were accessors (setters and/or 
      getters): everything else is handled by Jackson, by introspecting 
      resulting class, without having to even know there is anything special 
      about dynamically generated implementation class.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.5 Binary JSON (Smile format)&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Another important milestone with Jackson 1.6 was introduction of a 
      (then-) new binary data format called &lt;a href=&quot;http://wiki.fasterxml.com/SmileFormat&quot;&gt;Smile&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      Smile was borne out of my frustration with all the hype surrounding 
      Google's protobuf format: there was tons of hyperbole caused by the fact 
      that Google was opening up the data format they were using internally. 
      Protobuf itself is a simple and very reasonable binary data format, 
      suitable for encoding datagrams used for RPC. I call it &amp;quot;best of 80s 
      datagram technology&amp;quot;; not as an insult, but as a nod to maturity of the 
      idea -- it is automating things that back in 80s (and perhaps earlier) 
      were hand-coded whenever data communication was needed. Nothing wrong in 
      there.
    &lt;/p&gt;
    &lt;p&gt;
      But my frustration had more to do with creeping aspects of pre-mature 
      optimization; and the myopic view that binary formats were the only way 
      to achieve acceptable performance for high-volume communication. I 
      maintain that this is not true for general case.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      At the same time, there are valid benefits from proper use of efficient 
      binary encodings. And one approach that seemed attractive to me was that 
      of using &lt;i&gt;alternative physical encoding&lt;/i&gt; for representing existing 
      logical data model. This idea is hardly new; and it had been 
      demonstrated with XML, with BNUX, Fast Infoset and other approaches (all 
      that predate later sad effort known as EXI). But so far this had not 
      been tried with JSON -- sure, there is BSON, but it is not 1-to-1 
      mappable to JSON (despite what its name suggest), it is just another odd 
      (and very verbose) binary format.&lt;br&gt;So I thought that I should be able 
      to come up with a decent binary serialization format for JSON.
    &lt;/p&gt;
    &lt;p&gt;
      Timing for this effort was rather good, as I had joined &lt;a href=&quot;http://ning.com&quot;&gt;Ning&lt;/a&gt; 
      earlier that year, and had actual use case for Smile. At Ning Smile was 
      dynamically used for some high-volume systems, such as log aggregation 
      (think of systems like Kafka, Splunk). Smile turns out to work 
      particularly well when coupled with ultra-fast compression like LZF 
      (implemented at and for Ning as well!).
    &lt;/p&gt;
    &lt;p&gt;
      And beyond Ning, I had the fortune of working with creative genius(es) 
      behind &lt;a href=&quot;http://www.elasticsearch.org/&quot;&gt;ElasticSearch&lt;/a&gt;; this 
      was a match made in heaven, as they were just looking for an efficient 
      binary format to complement their use of JSON as external data format.
    &lt;/p&gt;
    &lt;p&gt;
      And what about the name? I think I need to credit mr. Sunny Gleason on 
      this; we brainstormed the idea, and it came about directly when we 
      considered what &amp;quot;magic cookie&amp;quot; (first 4 bytes used to identify format) 
      to use -- using a smiley seemed like a crazy enough idea to work. So 
      Smile encoded data literally &amp;quot;Starts With a Smile!&amp;quot; (check it out!)
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7.6 Modularity via Jackson Modules&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One more major area of innovation with Jackson 1.x series was that of 
      introduction of &amp;quot;Module&amp;quot; concept in &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease17&quot;&gt;Jackson 
      1.7&lt;/a&gt;. From design/architectural perspective, it is the most important 
      change during Jackson development.
    &lt;/p&gt;
    &lt;p&gt;
      The background to modules was my realization that I neither can nor want 
      to be the person trying to provide Jackson support for all useful Java 
      libraries; for datatypes like Joda, or Collection types of Guava. But 
      neither should users be left on their own, to have to write handlers for 
      things that do not (and often, can not) work out of the box.
    &lt;/p&gt;
    &lt;p&gt;
      But if not me or users, who would do it? The answer of &amp;quot;someone else&amp;quot; 
      does not sound great, until you actually think about it a bit. While I 
      think that the ideal case is that the library maintainers (of Joda, 
      Guava, etc) would do it, I think that the most &lt;b&gt;likely&lt;/b&gt; case is 
      that &amp;quot;someone with an itch&amp;quot; -- developer who happens to need JSON 
      serialization of, say, Joda datetime types -- is the person who can add 
      this support. The challenge, then, is that of co-operation: how could 
      this work be turned to something reusable, modular... something that 
      could essentially be released as a &amp;quot;mini-library&amp;quot; of its own?
    &lt;/p&gt;
    &lt;p&gt;
      This is where the simple interface known as Module comes in: it is 
      simply just a way to package necessary implementations of Jackson 
      handlers (serializers, deserializers, other components they rely on for 
      interfacing with Jackson), and to register them with Jackson, without 
      Jackson having any a priori knowledge of the extension in question. You 
      can think them of Jackson equivalent of plug-ins.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;8. Jackson 2.x&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Although there were more 1.x releases after 1.6, all introducing 
      important and interesting new features, focus during those releases 
      started to move towards bigger challenges regarding development. It was 
      also challenging to try to keep things backwards-compatible, as some 
      earlier API design (and occasionally implementation) decisions proved to 
      be sub-optimal. With this in mind, I started thinking about possibility 
      of making bigger change, making a major, somewhat backwards-incompatible 
      change.
    &lt;/p&gt;
    &lt;p&gt;
      The idea of 2.0 started maturing at around time of releasing Jackson 
      1.8; and so version 1.9 was designed with upcoming &amp;quot;bigger change&amp;quot; in 
      mind. It turns out that future-proofing is hard, and I don't know how 
      much all the planning helped. But I am glad that I thought through 
      multiple possible scenarios regarding potential ways versioning could be 
      handled.
    &lt;/p&gt;
    &lt;p&gt;
      The most important decision -- and one I think I did get right -- was to 
      change the Java and Maven packages Jackson 2.x uses: it should be (and 
      is!) possible to have both Jackson 1.x and Jackson 2.x implementations 
      in classpath, without conflicts. I have to thank my friend Brian 
      McCallister for this insight -- he convinced me that this is the only 
      sane way to go. And he is right. The alternative of just using the same 
      package name is akin to playing Russian Roulette: things MIGHT work, or 
      might not work. But you are actually playing with code of other people; 
      and they can't really be sure whether it will work for them without 
      trying... and often find out too late if it doesn't.
    &lt;/p&gt;
    &lt;p&gt;
      So although it is more work all around for cases where things would have 
      worked; it is definitely much, much less work and pain for cases where 
      you would have had problems with backwards compatibility. In fact, 
      amount of work is quite constant; and most changes are mechanical.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease20Features&quot;&gt;Jackson 2.0&lt;/a&gt; 
      took its time to complete; and was released February 2012.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;9. Jackson goes XML, CSV, YAML... and more&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One of biggest changes with Jackson 2.x has been the huge increase in 
      number of Modules. Many of these handle specific datatype libraries, 
      which is the original use case. Some modules implement new 
      functionality; Mr Bean, for example, which was introduced in 1.6 was 
      re-packaged as a Module in later releases.
    &lt;/p&gt;
    &lt;p&gt;
      But one of those Crazy Ideas (&amp;quot;what if...&amp;quot;) that I had somewhere during 
      1.x development was to consider possibility of supporting data formats 
      other than JSON.&lt;br&gt;It started with the obvious question of how to 
      support Smile format; but that was relatively trivial (although it did 
      need some changes to underlying system, to reduce deep coupling with 
      physical JSON content). Adding Smile support lead me to realize that the 
      only JSON-specific handling occurs at streaming API level: everything 
      above this level only deals with Token Streams. So what if... we simply 
      implemented alternative backends that can produce/consume token streams? 
      Wouldn't this allow data-binding to be used on data formats like YAML, 
      BSON and perhaps even XML?
    &lt;/p&gt;
    &lt;p&gt;
      Turns out it can, indeed -- and at this point, Jackson supports half a 
      dozen data formats beyond JSON (see &lt;a href=&quot;https://github.com/FasterXML/jackson&quot;&gt;here&lt;/a&gt;); 
      and more will be added over time.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;10. What Next?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      As of writing this entry I am working on Jackson 2.3; and list of 
      possible things to work on is as long as ever. Once upon a time (around 
      finalizing 1.0) I was under false impression that maybe I will be able 
      to wrap up work in a release or two, and move on. But given how many 
      feature-laden versions I have released since then, I no longer thing 
      that Jackson will be &amp;quot;complete&amp;quot; any time soon.
    &lt;/p&gt;
    &lt;p&gt;
      I hope to write more about Jackson future ... in (near I hope) future. I 
      hope above gave you more perspective on &amp;quot;where's Jackson been?&amp;quot;; and 
      perhaps can hint at where it is going as well.
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#479</link>
<guid>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#479</guid>

<category>Java</category>

<category>JSON</category>

<category>Open Source</category>

<category>Philosophic</category>

<pubDate>Thu, 08 Aug 2013 19:40:19 -0700</pubDate>
</item>

<item>
<title>Jackson 2.1 was released... quite a while ago :)</title>
<description>&lt;p&gt;
      Ok, so I have not been an active blogger for a while. Like, since about 
      a year ago. I am hoping to catch up a bit, so let's start with 
      intermediate Jackson releases that have gone out the door since I last 
      wrote about Jackson.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Jackson 2.1&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Version 2.1 was released almost a year ago, October 2012. After big bang 
      of 2.0 release -- what with all the crazy new features like Object Id 
      handling (for fully cyclic object graphs), 2.1 was expected to be more 
      minor release in every way.
    &lt;/p&gt;
    &lt;p&gt;
      But, that was not to be... instead, 2.1 packed an impressive set of 
      improvements of its own.&lt;br&gt;Focus was on general usability: improved 
      ergonomics, bit of performance improvements (for data-binding) and the 
      usual array of bug fixes that required bigger changes in internals (and 
      occasionally additional API) than what can be done in a patch release.&lt;br&gt;
    &lt;/p&gt;
    &lt;p&gt;
      For more complete handling of what exactly was added, you can check out 
      my &lt;a href=&quot;https://github.com/FasterXML/jackson-docs/wiki/Presentation-Jackson-2.1-Overview&quot;&gt;Jackson 
      2.1 Overview&lt;/a&gt; presentation I gave at &lt;a href=&quot;http://www.wordnik.com/&quot;&gt;Wordnik&lt;/a&gt; 
      (thanks Tony and folks!). Note that links to this and other 
      presentations can be found from &lt;a href=&quot;https://github.com/FasterXML/jackson-docs&quot;&gt;Jackson 
      Docs&lt;/a&gt; github repo.&lt;br&gt;For full list of changes, check &lt;a href=&quot;http://wiki.fasterxml.com/JacksonRelease21&quot;&gt;2.1 
      Release Notes&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      But here's a Reader's Digest version.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Shape-shifting&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;i&gt;@JsonFormat&lt;/i&gt; annotation was added in Jackson 2.0, but was not used 
      by many datatypes. With 2.1, there are interesting (and back then, 
      experimental; but it is much more stable now!) new features to let you 
      change the &amp;quot;shape&amp;quot; (JSON Structure) of some of common Java datatypes:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        Serialize Enums as JSON Objects instead of Strings: useful for 
        serialization, but can not deserialize back (how would that work? 
        Enums are singletons)
      &lt;/li&gt;
      &lt;li&gt;
        Collections (Sets, Lists) as JSON Objects (instead of arrays): useful 
        for custom Collections that add extra properties -- can also 
        deserialize, with proper use of @JsonCreator annotations (or custom 
        deserializer)
      &lt;/li&gt;
      &lt;li&gt;
        POJOs as Arrays! Instead of having name/value pairs, you will get JSON 
        arrays where position indicates which property is being used (make 
        sure to use @JsonPropertyOrder annotation to define ordering!)
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      Of these, the last option is probably the most interesting. It can make 
      JSON as compact as CSV; and in fact can compete with binary formats in 
      many cases, especially if values are mostly Strings.&lt;br&gt;A simple example 
      would be:
    &lt;/p&gt;
    &lt;pre&gt;  @JsonFormat(shape=JsonFormat.Shape.ARRAY)
  @JsonPropertyOrder(alphabetic=true)
  public class Point {
    public int x, y;
  }&lt;/pre&gt;
    &lt;p&gt;
      which, when serialized, could look like:
    &lt;/p&gt;
    &lt;pre&gt;  [ 1, 2]&lt;/pre&gt;
    &lt;p&gt;
      instead of earlier
    &lt;/p&gt;
    &lt;pre&gt;  { &amp;quot;x&amp;quot;:1, &amp;quot;y&amp;quot;:2 }&lt;/pre&gt;
    &lt;p&gt;
      and obviously works for reading as well (that is, you can read such 
      tabular data back).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Chunked (partial) Binary Data reads, writes&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      When dealing with really large data, granularity of &lt;i&gt;JsonParser&lt;/i&gt; 
      and &lt;i&gt;JsonGenerator&lt;/i&gt; works well, except for case of long JSON 
      Strings; for example, ones that contain Base64-encoded data. Since these 
      values may be potentially very large, and since they are quite often 
      just stored on disk (or read from disk to send) -- and there is no 
      benefit from keeping the whole value in memory at all -- it makes sense 
      to offer some way to allow streaming for values, not just between values.
    &lt;/p&gt;
    &lt;p&gt;
      To this end, JsonParser and JsonGenerator now do have methods that allow 
      one to read and write large binary data chunks without retaining more 
      than a limited amount of data in memory (one buffer-full, like 8 or 
      16kB) at any given point. Access is provided via &lt;i&gt;java.io.InputStream&lt;/i&gt; 
      and &lt;i&gt;java.io.OutputStream&lt;/i&gt;, with methods:
    &lt;/p&gt;
    &lt;p&gt;
      JsonParser.readBinaryValue(OutputStream)&lt;br&gt;JsonGenerator.writeBinary(InputStream, 
      int expectedLength)
    &lt;/p&gt;
    &lt;p&gt;
      Note that while direction of arguments may look odd, it actually makes 
      sense when you try using it: you will provide handler for content (which 
      implements OutputStream), and source for content to write (InputStream).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. Format auto-detection support for data-binding&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Another innovative new feature is ability to use already existing data 
      format auto-detection, without having to use Streaming API. Earlier 
      versions included support for &lt;i&gt;JsonParser&lt;/i&gt; auto-detecting type of 
      input, for data formats that support this (some binary formats do not; I 
      consider this a flaw in such formats; of text formats, CSV does not): at 
      least JSON, XML, Smile and YAML support auto-detection.
    &lt;/p&gt;
    &lt;p&gt;
      You enable support through &lt;i&gt;ObjectReader&lt;/i&gt; for example like so:
    &lt;/p&gt;
    &lt;pre&gt;  ObjectMapper mapper = new ObjectMapper();
  XmlMapper xmlMapper = new XmlMapper(); // XML is special: must start with its own mapper
  ObjectReader reader = mapper
    .reader(POJO.class) // for reading instances of POJO
    .withFormatDetection(new JsonFactory(), xmlMapper.getFactory(), new SmileFactory();&lt;/pre&gt;
    &lt;p&gt;
      and then you can use resulting reader normally:&lt;br&gt;
    &lt;/p&gt;
    &lt;pre&gt;  User user = mapper.readValue(new File(&amp;quot;input.raw&amp;quot;), User.class);&lt;/pre&gt;
    &lt;p&gt;
      and input that is in XML, JSON or Smile format will be property decoded, 
      and bound to resulting class. I personally use this to support 
      transparent usage of Smile (binary JSON) format as a pluggable 
      optimization over JSON.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. Much improved XML module&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Although XML module has existed since earlier 1.x versions, 2.0 provided 
      first solid version. But it did not include support for one commonly 
      used JAXB feature: ability to use so-called &amp;quot;unwrapped&amp;quot; Lists. 2.1 fixes 
      this and fully supports both wrapped and unwrapped Lists.
    &lt;/p&gt;
    &lt;p&gt;
      But beyond this feature, testing was significantly extended, and a few 
      specific bugs were fixed. As a result version 2.1 is the first version 
      that I can fully recommend as replacement for JAXB processing in 
      production environments.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. Delegating serializer, deserializer&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Final new feature is support for so-called delegating serializers and 
      deserializers. The basic idea is simple: instead of having to build 
      fully custom handlers you only need to implement converters that can 
      convert your custom types into something that Jackson can automatically 
      handle (supports out of the box).
    &lt;/p&gt;
    &lt;p&gt;
      Details of this are included in &lt;a href=&quot;https://github.com/FasterXML/jackson-docs/wiki/Presentation-Jackson-2.1-Overview&quot;&gt;2.1 
      presentation&lt;/a&gt;; most commonly you will just extend &lt;i&gt;com.fasterxml.jackson.databind.deser.std.StdDelegatingDeserializer&lt;/i&gt; 
      and &lt;i&gt;com.fasterxml.jackson.databind.ser.std.StdDelegatingSerializer&lt;/i&gt;.
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#478</link>
<guid>http://www.cowtowncoder.com/blog/archives/08-01-2013_08-31-2013.html#478</guid>

<category>Java</category>

<category>JSON</category>

<category>Open Source</category>

<pubDate>Sat, 03 Aug 2013 18:48:02 -0700</pubDate>
</item>

<item>
<title>Replacing standard JDK serialization using Jackson (JSON/Smile), java.io.Externalizable</title>
<description>&lt;p&gt;
      &lt;b&gt;1. Background&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The default Java serialization provided by JDK is a two-edged sword: on 
      one hand, it is a simple, convenient way to &amp;quot;freeze and thaw&amp;quot; Objects 
      you have, handling about any kind of Java object graphs. It is possibly 
      the most powerful serialization mechanism on Java platform, bar none.
    &lt;/p&gt;
    &lt;p&gt;
      But on the other hand, its shortcomings are well-document (and I hope, 
      well-known) at this point. Problems include:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        Poor space-efficiency (especially for small data), due to inclusion of 
        all class metadata: that is, size of output can be huge, larger than 
        about any alternative, including XML
      &lt;/li&gt;
      &lt;li&gt;
        Poor performance (especially for small data), partly due to size 
        inefficiency
      &lt;/li&gt;
      &lt;li&gt;
        Brittleness: smallest changes to class definitions may break 
        compatibility, preventing deserialization. This makes it a poor choice 
        for both data exchange between (Java) systems as well as long-term 
        storage
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      Still, the convenience factor has led to many systems using JDK 
      serialization to be the default serialization method to use.
    &lt;/p&gt;
    &lt;p&gt;
      Is there anything we could do to address downsides listed above? Plenty, 
      actually. Although there is no way to do much more for the default 
      implementation (JDK serialization implementation is in fact ridiculously 
      well optimized for what it tries to achieve -- it's just that the goal 
      is very ambitious), one can customize what gets used by making objects 
      implement j&lt;b&gt;ava.io.Externalizable&lt;/b&gt; interface. If so, JDK will 
      happily use alternate implementation under the hood.
    &lt;/p&gt;
    &lt;p&gt;
      Now: although writing custom serializers may be fun sometimes -- and for 
      specific case, you can actually write very efficient solution as well, 
      given enough time -- it would be nice if you could use an existing 
      component to address listed short-comings.
    &lt;/p&gt;
    &lt;p&gt;
      And that's what we'll do! Here's one possible way to improve on all 
      problems listed above:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        Use an efficient Jackson serializer (to produce either JSON, or 
        perhaps more interestingly, &lt;a href=&quot;http://wiki.fasterxml.com/SmileFormat&quot;&gt;Smile&lt;/a&gt; 
        binary data)
      &lt;/li&gt;
      &lt;li&gt;
        Wrap it in nice java.io.Externalizable, to make it transparent to code 
        using JDK serialization (albeit not transparent for maintainers of the 
        class -- but we will try minimizing amount of intrusive code)
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      &lt;b&gt;2. Challenges with java.io.Externalizable&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      First things first: while conceptually simple, there are couple of 
      rather odd design decisions that make use of java.io.Externalizable bit 
      tricky:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        Instead of passing instances of &lt;b&gt;java.io.InputStream&lt;/b&gt;, &lt;b&gt;java.io.OutputStream&lt;/b&gt;, 
        instead &lt;b&gt;java.io.ObjectOutput&lt;/b&gt; and &lt;b&gt;java.io.ObjectInput&lt;/b&gt; are 
        used; and they do NOT extend stream versions (even though they define 
        mostly same methods!). This means additional wrapping is needed
      &lt;/li&gt;
      &lt;li&gt;
        &lt;b&gt;Externalizable.readExternal()&lt;/b&gt; requires updating of the object 
        itself, not that of constructing new instances: most serialization 
        frameworks do not support such operation
      &lt;/li&gt;
      &lt;li&gt;
        How to access external serialization library, as no context is passed 
        to either of methods?
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      These are not fundamental problems for Jackson: first one requires use 
      of adapter classes (see below), second that we need to use &amp;quot;updating 
      reader&amp;quot; approach that Jackson was supported for a while (yay!). And to 
      solve the third part, we have at least two choices: use of ThreadLocal 
      for passing an ObjectMapper; or, use of a static helper class (approach 
      shown below)
    &lt;/p&gt;
    &lt;div&gt;
      
    &lt;/div&gt;
    &lt;div&gt;
      So here are the helper classes we need:
    &lt;/div&gt;
    &lt;div&gt;
      &lt;hr&gt;
      
    &lt;/div&gt;
    &lt;pre&gt;final static class ExternalizableInput extends InputStream
{
  private final ObjectInput in;

  public ExternalizableInput(ObjectInput in) {
   this.in = in;
  }

  @Override
  public int available() throws IOException {
    return in.available();
  }

  @Override
  public void close() throws IOException {
    in.close();
  }

  @Override
  public boolean  markSupported() {
    return false;
  }

  @Override
  public int read() throws IOException {
   return in.read();
  }

  @Override
  public int read(byte[] buffer) throws IOException {
    return in.read(buffer);
  }

  @Override
  public int read(byte[] buffer, int offset, int len) throws IOException {
    return in.read(buffer, offset, len);
  }

  @Override
  public long skip(long n) throws IOException {
   return in.skip(n);
  }
}&lt;br&gt;&lt;br&gt;final static class ExternalizableOutput extends OutputStream
{
  private final ObjectOutput out;

  public ExternalizableOutput(ObjectOutput out) {
   this.out = out;
  }

@Override
public void flush() throws IOException {
out.flush();
}

@Override
public void close() throws IOException {
out.close();
}

@Override
public void write(int ch) throws IOException {
out.write(ch);
}

@Override
public void write(byte[] data) throws IOException {
out.write(data);
}

@Override
public void write(byte[] data, int offset, int len) throws IOException {
out.write(data, offset, len);
}
}&lt;br&gt;&lt;br&gt;/* Use of helper class here is unfortunate, but necessary; alternative would&lt;br&gt; * be to use ThreadLocal, and set instance before calling serialization.&lt;br&gt; * Benefit of that approach would be dynamic configuration; however, this&lt;br&gt; * approach is easier to demonstrate.&lt;br&gt; */&lt;br&gt;class MapperHolder {
  private final ObjectMapper mapper = new ObjectMapper();
  private final static MapperHolder instance = new MapperHolder();
  public static ObjectMapper mapper() { return instance.mapper; }
}&lt;br&gt;&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      and given these classes, we can implement 
      Jackson-for-default-serialization solution.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Let's Do a Serialization!&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      So with that, here's a class that is serializable using Jackson JSON 
      serializer:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;  static class MyPojo implements Externalizable
  {
        public int id;
        public String name;
        public int[] values;

        public MyPojo() { } // for deserialization
        public MyPojo(int id, String name, int[] values)
        {
            this.id = id;
            this.name = name;
            this.values = values;
        }

        public void readExternal(ObjectInput in) throws IOException {
            MapperHolder.mapper().readerForUpdating(this).readValue(new ExternalizableInput(in));&lt;br&gt;        }
        public void writeExternal(ObjectOutput oo) throws IOException {
            MapperHolder.mapper().writeValue(new ExternalizableOutput(oo), this);
        }&lt;br&gt;  }
&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      to use that class, use JDK serialization normally:
    &lt;/p&gt;
    &lt;div&gt;
      &lt;hr&gt;
      
    &lt;/div&gt;
    &lt;pre&gt;  // serialize as bytes (to demonstrate):&lt;br&gt;  MyPojo input = new MyPojo(13, &amp;quot;Foobar&amp;quot;, new int[] { 1, 2, 3 } );
  ByteArrayOutputStream bytes = new ByteArrayOutputStream();
  ObjectOutputStream obs = new ObjectOutputStream(bytes);
  obs.writeObject(input);
  obs.close();
  byte[] ser = bytes.toByteArray();&lt;br&gt;&lt;br&gt;  // and to get it back:&lt;br&gt;  ObjectInputStream ins = new ObjectInputStream(new ByteArrayInputStream(ser));
  MyPojo output = (MyPojo) ins.readObject();&lt;br&gt;  ins.close();&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      And that's it.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. So what's the benefit?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      At this point, you may be wondering if and how this would actually help 
      you. Since JDK serialization is using binary format; and since 
      (allegedly!) textual formats are generally more verbose than binary 
      formats, how could this possibly help with size of performance?
    &lt;/p&gt;
    &lt;p&gt;
      Turns out that if you test out code above and compare it with the case 
      where class does NOT implement Externalizable, sizes are:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        Default JDK serialization: 186 bytes
      &lt;/li&gt;
      &lt;li&gt;
        Serialization as embedded JSON: 130 bytes
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      Whoa! Quite unexpected result? JSON-based alternative &lt;i&gt;30% SMALLER&lt;/i&gt; 
      than JDK serialization!
    &lt;/p&gt;
    &lt;p&gt;
      Actually, not really. The problem with JDK serialization is not the way 
      data is stored, but rather the fact that in addition to (compact) data, 
      much of Class definition metadata is included. This metadata is needed 
      to guard against Class incompatibilities (which it can do pretty well), 
      but it comes with a cost. And that cost is particularly high for small 
      data.
    &lt;/p&gt;
    &lt;p&gt;
      Similarly, performance typically follows data size: while I don't have 
      publishable results (I may do that for a future post), I expect 
      embedded-JSON to also perform significantly better for single-object 
      serialization use cases.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. Further ideas: Smile!&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      But perhaps you think we should be able to do better, size-wise (and 
      perhaps performance) than using JSON?
    &lt;/p&gt;
    &lt;p&gt;
      Absolutely. Since the results are not exactly readable (to use 
      Externalizable, bit of binary data will be used to indicate class name, 
      and little bit of stream metadata), we probably do not greatly care what 
      the actual underlying format is.&lt;br&gt;With this, an obvious choice would 
      be to use &lt;a href=&quot;http://wiki.fasterxml.com/SmileFormat&quot;&gt;Smile data 
      format&lt;/a&gt;, binary counterpart to JSON, a format that Jackson supports 
      100% with &lt;a href=&quot;https://github.com/FasterXML/jackson-dataformat-smile&quot;&gt;Smile 
      Module&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      The only change that is needed is to replace the first line from 
      &amp;quot;MapperHolder&amp;quot; to read:
    &lt;/p&gt;
    &lt;p&gt;
       &lt;i&gt; private final ObjectMapper mapper = new ObjectMapper(new 
      SmileFactory());&lt;/i&gt;
    &lt;/p&gt;
    &lt;p&gt;
      and we will see even reduced size, as well as faster reading and writing 
      -- Smile is typically 30-40% smaller in size, and 30-50% faster to 
      process than JSON.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. Even More compact? Consider Jackson 2.1, &amp;quot;POJO as array!&amp;quot;&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      But wait! In very near future, we may be able to do EVEN BETTER! Jackson 
      2.1 (see the &lt;a href=&quot;https://github.com/FasterXML/jackson-docs/wiki/Presentation-Jackson-2.1-Preview&quot;&gt;Sneak 
      Peek&lt;/a&gt;) will introduce one interesting feature that will further 
      reduce size of JSON/Smile Object serialization. By using following 
      annotation:
    &lt;/p&gt;
    &lt;p&gt;
        &lt;i&gt;@JsonFormat(shape=JsonFormat.Shape.OBJECT)   &lt;/i&gt;
    &lt;/p&gt;
    &lt;p&gt;
      you can further reduce the size: this occurs as the property names are 
      excluded from serialization (think of output similar to CSV, just using 
      JSON Arrays).
    &lt;/p&gt;
    &lt;p&gt;
      For our toy use case, size is reduced further from 130 bytes to 109; 
      further reduction of almost 20%. But wait! It gets better -- same will 
      be true for Smile as well, since while it can reduce space in general, 
      it still has to retain some amount of name information normally; but 
      with POJO-as-Arrays it will use same exclusion!
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7. But how about actual real-life results?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      At this point I am actually planning on doing something based on code I 
      showed above. But planning is in early stages so I do not yet have 
      results from &amp;quot;real data&amp;quot;; meaning objects of more realistic sizes. But I 
      hope to get that soon: the use case is that of storing entities (data 
      for which is read from DB) in memcache. Existing system is getting 
      CPU-bound both from basic serialization/deserialization activity, but 
      especially from higher number of GCs. I fully expect the new approach to 
      help with this; and most importantly, be quite easy to deploy: this 
      because I do not have to change any of code that actually 
      serializes/deserializes Beans -- I just have to modify Beans themselves 
      a bit.
    &lt;/p&gt;
    &lt;p&gt;
      
    &lt;/p&gt;
    &lt;p&gt;
      
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/08-01-2012_08-31-2012.html#477</link>
<guid>http://www.cowtowncoder.com/blog/archives/08-01-2012_08-31-2012.html#477</guid>

<category>Java</category>

<category>JSON</category>

<category>Performance</category>

<pubDate>Sat, 18 Aug 2012 16:26:39 -0700</pubDate>
</item>

<item>
<title>Forcing escaping of HTML characters (less-than, ampersand) in JSON using Jackson</title>
<description>&lt;p&gt;
      &lt;b&gt;1. The problem&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;http://wiki.fasterxml.com/JacksonHome&quot;&gt;Jackson&lt;/a&gt; handles 
      escaping of JSON String values in minimal way using escaping where 
      absolutely necessary: it escapes two characters by default -- double 
      quotes and backslash -- as well as non-visible control characters. But 
      it does not escape other characters, since this is not required for 
      producing valid JSON documents.
    &lt;/p&gt;
    &lt;p&gt;
      There are systems, however, that may run into problems with some 
      characters that are valid in JSON documents. There are also use cases 
      where you might prefer to add more escaping. For example, if you are to 
      enclose a JSON fragment in XML attribute (or Javascript code), you might 
      want to use apostrophe (') as quote character in XML, and force escaping 
      of all apostrophes in JSON content; this allows you to simple embed 
      encoded JSON value without other transformations.
    &lt;/p&gt;
    &lt;p&gt;
      Another specific use case is that of escaping &amp;quot;HTML funny characters&amp;quot;, 
      like less-than, greater-than, ampersand and apostrophe characters 
      (double-quote are escaped by default).
    &lt;/p&gt;
    &lt;p&gt;
      Let's see how you can do that with Jackson.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Not as easy to change as you might think&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Your first thought may be that of &amp;quot;I'll just do it myself&amp;quot;. The problem 
      is two-fold:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        When using API via data-binding, or regular Streaming generator, you 
        must pass unescaped String, and it will get escaped using Jackson's 
        escaping mechanism -- you can not pre-process it (*)
      &lt;/li&gt;
      &lt;li&gt;
        If you decide to post-process content after JSON gets written, you 
        need to be careful with replacements, and this will have negative 
        impact on performance (i.e. it is likely to double time serialization 
        takes)
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      (*) actually, there is method 'JsonGenerator.writeRaw(...)' which you 
      can use to force exact details, but its use is cumbersome and you can 
      easily break things if you are not careful. Plus it is only applicable 
      via Streaming API
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Jackson (1.8) has you covered&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Luckily, there is no need for you to write custom post-processing code 
      to change details of content escaping.
    &lt;/p&gt;
    &lt;p&gt;
      Version 1.8 of Jackson added a feature to let users customize details of 
      escaping of characters in JSON String values.&lt;br&gt;This is done by 
      defining a &lt;b&gt;CharacterEscapes&lt;/b&gt; object to be used by &lt;b&gt;JsonGenerator&lt;/b&gt;; 
      it is registered on &lt;b&gt;JsonFactory&lt;/b&gt;. If you use data-binding, you can 
      set this by using &lt;b&gt;ObjectMapper.getJsonFactory()&lt;/b&gt; first, then 
      define CharacterEscapes to use.
    &lt;/p&gt;
    &lt;p&gt;
      Functionality is handled at low-level, during writing of JSON String 
      values; and CharacterEscapes abstract class is designed in a way to 
      minimize performance overhead.&lt;br&gt;While there is some performance 
      overhead (little bit of additional processing is required), it should 
      not have significant impact unless significant portion of content 
      requires escaping.&lt;br&gt;As usual, if you care a lot about performance, you 
      may want to measure impact of the change with test data.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. The Code&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Here is a way to force escaping of HTML &amp;quot;funny characters&amp;quot;, using 
      functionality Jackson 1.8 (and above) have.
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;import org.codehaus.jackson.SerializableString;
import org.codehaus.jackson.io.CharacterEscapes;
&lt;br&gt;// First, definition of what to escape
public class HTMLCharacterEscapes extends CharacterEscapes
{
    private final int[] asciiEscapes;
    
    public HTMLCharacterEscapes()
    {&lt;br&gt;        // start with set of characters known to require escaping (double-quote, backslash etc)
        int[] esc = CharacterEscapes.standardAsciiEscapesForJSON();&lt;br&gt;        // and force escaping of a few others:
        esc['&amp;lt;'] = CharacterEscapes.ESCAPE_STANDARD;
        esc['&amp;gt;'] = CharacterEscapes.ESCAPE_STANDARD;
        esc['&amp;amp;'] = CharacterEscapes.ESCAPE_STANDARD;
        esc['\''] = CharacterEscapes.ESCAPE_STANDARD;
        asciiEscapes = esc;
    }&lt;br&gt;    // this method gets called for character codes 0 - 127
    @Override public int[] getEscapeCodesForAscii() {
        return asciiEscapes;
    }&lt;br&gt;    // and this for others; we don't need anything special here
    @Override public SerializableString getEscapeSequence(int ch) {
        // no further escaping (beyond ASCII chars) needed:
        return null;
    }
}&lt;br&gt;&lt;br&gt;// and then an example of how to apply it&lt;br&gt;public ObjectMapper getEscapingMapper() {&lt;br&gt;    ObjectMapper mapper = new ObjectMapper();&lt;br&gt;    mapper.getJsonFactory().setCharacterEscapes(new HTMLCharacterEscapes());&lt;br&gt;    return mapper;&lt;br&gt;}&lt;br&gt;&lt;br&gt;// so we could do:&lt;br&gt;public byte[] serializeWithEscapes(Object ob) throws IOException&lt;br&gt;{&lt;br&gt;    return getEscapingMapper().writeValueAsBytes(ob);&lt;br&gt;}&lt;br&gt;&lt;br&gt;&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      And that's it.
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/08-01-2012_08-31-2012.html#476</link>
<guid>http://www.cowtowncoder.com/blog/archives/08-01-2012_08-31-2012.html#476</guid>

<category>JSON</category>

<pubDate>Sat, 18 Aug 2012 15:14:21 -0700</pubDate>
</item>

<item>
<title>Doing actual non-blocking, incremental HTTP access with async-http-client</title>
<description>&lt;p&gt;
      &lt;a href=&quot;https://github.com/sonatype/async-http-client&quot;&gt;Async-http-client&lt;/a&gt; 
      library, originally developed at Ning (by Jean-Francois, Tom, Brian and 
      maybe others and since then by quite a few others) has been around for a 
      while now.&lt;br&gt;Its main selling point is the claim for better scalability 
      compared to alternatives like &lt;a href=&quot;http://hc.apache.org/&quot;&gt;Jakarta 
      HTTP Client&lt;/a&gt; (this is not the only selling points: its API also seems 
      more intuitive).
    &lt;/p&gt;
    &lt;p&gt;
      But although library itself is capable of working well in non-blocking 
      mode, most examples (and probably most users) use it in plain old 
      blocking mode; or at most use Future to simply defer handling of 
      respoonses, but without handling content incrementally when it becomes 
      available.
    &lt;/p&gt;
    &lt;p&gt;
      While this lack of documentation is bit unfortunate just in itself, the 
      bigger problem is that most usage as done by sample code requires 
      reading the whole response in memory.&lt;br&gt;This may not be a big deal for 
      small responses, but in cases where response size is in megabytes, this 
      often becomes problematic.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Blocking, fully in-memory usage&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The usual (and potentially problematic) usage pattern is something like:
    &lt;/p&gt;
    &lt;pre&gt;  AsyncHttpClient asyncHttpClient = new AsyncHttpClient();
  Future&amp;lt;Response&amp;gt; f = asyncHttpClient.prepareGet(&amp;quot;http://www.ning.com/ &amp;quot;).execute();
  Response r = f.get();&lt;br&gt;  byte[] contents = r.getResponseBodyAsBytes();&lt;/pre&gt;
    &lt;p&gt;
      which gets the whole response as a byte array; no surprises there.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Use InputStream to avoid buffering the whole entity?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The first obvious work around attempt is to have a look at Response 
      object, and notice that there is method &amp;quot;&lt;i&gt;getResponseBodyAsStream()&lt;/i&gt;&amp;quot;. 
      This would seemingly allow one to read response, piece by piece, and 
      process it incrementally, by (for example) writing it to a file.
    &lt;/p&gt;
    &lt;p&gt;
      Unfortunately, this method is just a facade, implemented like so:
    &lt;/p&gt;
    &lt;pre&gt; public InputStream getResponseBodyAsStream() {&lt;br&gt;   return new ByteArrayInputStream(getResponseBodyAsBytes());&lt;br&gt; }&lt;/pre&gt;
    &lt;p&gt;
      which actually is no more efficient than accessing the whole content as 
      a byte array. :-/
    &lt;/p&gt;
    &lt;p&gt;
      (why is it implemented that way? Mostly because underlying non-blocking 
      I/O library, like Netty or Grizzly, provides content using &amp;quot;push&amp;quot; style 
      interface, which makes it very hard to support &amp;quot;pull&amp;quot; style abstractions 
      like java.io.InputStream -- so it is not really AHC's fault, but rather 
      a consequence of NIO/async style of I/O processing)
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Go fully async&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      So what can we do to actually process large response payloads (or large 
      PUT/POST request payloads, for that matter)?
    &lt;/p&gt;
    &lt;p&gt;
      To do that, it is necessary to use following callback abstractions:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        To handle response payloads (for HTTP GETs), we need to implement &lt;b&gt;&lt;i&gt;AsyncCompletionHandler&lt;/i&gt;&lt;/b&gt; 
        interface.
      &lt;/li&gt;
      &lt;li&gt;
        To handle PUT/POST request payloads, we need to implement &lt;b&gt;&lt;i&gt;BodyGenerator&lt;/i&gt;&lt;/b&gt; 
        (which is used for creating a Body instance, abstraction for feeding 
        content)
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      Let's have a look at what is needed for the first case.
    &lt;/p&gt;
    &lt;p&gt;
      (note: there are existing default implementations for some of the pieces 
      -- but here I will show how to do it from ground up) 
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. A simple download-a-file example&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Let's start with a simple case of downloading a large file into a file, 
      without keeping more than a small chunk in memory at any given time. 
      This can be done as follows:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;public class SimpleFileHandler implements AsyncHandler&amp;lt;File&amp;gt;
{
 private File file;
 private final FileOutputStream out;
 private boolean failed = false;

 public SimpleFileHandler(File f) throws IOException {
  file = f;
  out = new FileOutputStream(f);
 }

 public com.ning.http.client.AsyncHandler.STATE onBodyPartReceived(HttpResponseBodyPart part)
   throws IOException
 {
  if (!failed) {
   part.writeTo(out);
  }
  return STATE.CONTINUE;
 }

 public File onCompleted() throws IOException {
  out.close();
  if (failed) {
   file.delete();
   return null;
  }
  return file;
 }

 public com.ning.http.client.AsyncHandler.STATE onHeadersReceived(HttpResponseHeaders h) {
  // nothing to check here as of yet
  return STATE.CONTINUE;
 }

 public com.ning.http.client.AsyncHandler.STATE onStatusReceived(HttpResponseStatus status) {
  failed = (status.getStatusCode() != 200);
  return failed ?  STATE.ABORT : STATE.CONTINUE;
 }

 public void onThrowable(Throwable t) {
  failed = true;
 }
}&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      Voila. Code is not very brief (event-based code seldom is), and it could 
      use some more handling for error cases.&lt;br&gt;But it should at least show 
      the general processing flow -- nothing very complicated there, beyond 
      basic state machine style operation.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. Booooring. Anything more complicated?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Downloading a large file is something useful, but while not a contriver 
      example, it is rather plain. So let's consider the case where we not 
      only want to download a piece of content, but also want uncompress it, 
      in one fell swoop. This serves as an example of additional processing we 
      may want to do, in incremental/streaming fashion -- as an alternative to 
      having to store an intermediate copy in a file, then uncompress to 
      another file.
    &lt;/p&gt;
    &lt;p&gt;
      But before showing the code, however, it is necessary to explain why 
      this is bit tricky.
    &lt;/p&gt;
    &lt;p&gt;
      First, remember that we can't really use &lt;i&gt;InputStream&lt;/i&gt;-based 
      processing here: all content we get is &amp;quot;pushed&amp;quot; to use (without our code 
      ever blocking with input); whereas InputStream would want to push 
      content itself, possibly blocking the thread.
    &lt;/p&gt;
    &lt;p&gt;
      Second: most decompressors present either InputStream-based abstraction, 
      or uncompress-the-whole-thing interface: neither works for us, since we 
      are getting incremental chunks; so to use either, we would first have to 
      buffer the whole content. Which is what we are trying to avoid.
    &lt;/p&gt;
    &lt;p&gt;
      As luck would have it, however, &lt;a href=&quot;https://github.com/ning/compress&quot;&gt;Ning 
      Compress&lt;/a&gt; package (version 0.9.4, specifically) just happens to have 
      a push-style uncompressor interface (aptly named as &amp;quot;&lt;b&gt;&lt;i&gt;com.ning.compress.Uncompressor&lt;/i&gt;&lt;/b&gt;&amp;quot;); 
      and two implementations:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        com.ning.compress.lzf.LZFUncompressor
      &lt;/li&gt;
      &lt;li&gt;
        com.ning.compress.gzip.GZIPUncompressor (uses JDK native zlib under 
        the hood)
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      So why is that fortunate? Because interface they expose is push style:
    &lt;/p&gt;
    &lt;pre&gt; public abstract class Uncompressor
 {
  public abstract void feedCompressedData(byte[] comp, int offset, int len) throws IOException;
  public abstract void complete() throws IOException;&lt;br&gt; }&lt;/pre&gt;
    &lt;p&gt;
      and is thereby usable to our needs here. Especially when we use 
      additional class called &amp;quot;UncompressorOutputStream&amp;quot;, which makes an 
      OutputStream out of Uncompressor and target stream (which is needed for 
      efficient access to content AHC exposes via &lt;i&gt;HttpResponseBodyPart&lt;/i&gt;)
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. Show me the code&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Here goes:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;public class UncompressingFileHandler implements AsyncHandler&amp;lt;File&amp;gt;,
   DataHandler // for Uncompressor
{
 private File file;
 private final OutputStream out;
 private boolean failed = false;
 private final UncompressorOutputStream uncompressingStream;

 public UncompressingFileHandler(File f) throws IOException {
  file = f;
  out = new FileOutputStream(f);
 }

 public com.ning.http.client.AsyncHandler.STATE onBodyPartReceived(HttpResponseBodyPart part)
   throws IOException
 {
  if (!failed) {
   // if compressed, pass through uncompressing stream
   if (uncompressingStream != null) {
    part.writeTo(uncompressingStream);
   } else { // otherwise write directly
    part.writeTo(out);
   }
   part.writeTo(out);
  }
  return STATE.CONTINUE;
 }

 public File onCompleted() throws IOException {
  out.close();
  if (uncompressingStream != null) {
   uncompressingStream.close();
  }
  if (failed) {
   file.delete();
   return null;
  }
  return file;
 }

 public com.ning.http.client.AsyncHandler.STATE onHeadersReceived(HttpResponseHeaders h) {
  // must verify that we are getting compressed stuff here:
  String compression = h.getHeaders().getFirstValue(&amp;quot;Content-Encoding&amp;quot;);
  if (compression != null) {
   if (&amp;quot;lzf&amp;quot;.equals(compression)) {
    uncompressingStream = new UncompressorOutputStream(new LZFUncompressor(this));
   } else if (&amp;quot;gzip&amp;quot;.equals(compression)) {
    uncompressingStream = new UncompressorOutputStream(new GZIPUncompressor(this));
   }
  }
  // nothing to check here as of yet
  return STATE.CONTINUE;
 }

 public com.ning.http.client.AsyncHandler.STATE onStatusReceived(HttpResponseStatus status) {
  failed = (status.getStatusCode() != 200);
  return failed ?  STATE.ABORT : STATE.CONTINUE;
 }

 public void onThrowable(Throwable t) {
  failed = true;
 }

 // DataHandler implementation for Uncompressor; called with uncompressed content:
 public void handleData(byte[] buffer, int offset, int len) throws IOException {
  out.write(buffer, offset, len);
 }
}&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      Handling gets bit more complicated here, since we have to handle both 
      case where content is compressed; and case where it is not (since server 
      is ultimately responsible for applying compression or not).
    &lt;/p&gt;
    &lt;p&gt;
      And to make call, you also need to indicate capability to accept 
      compressed data. For example, we could define a helper method like:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;public File download(String url) throws Exception
{
 AsyncHttpClient ahc = new AsyncHttpClient();
 Request req = ahc.prepareGet(url)
  .addHeader(&amp;quot;Accept-Encoding&amp;quot;, &amp;quot;lzf,gzip&amp;quot;)
  .build();
 ListenableFuture&amp;lt;File&amp;gt; futurama = ahc.executeRequest(req,&lt;br&gt;   new UncompressingFileHandler(new File(&amp;quot;download.txt&amp;quot;)));

 try { // wait for 30 seconds to complete
  return futurama.get(30, TimeUnit.MILLISECONDS);
 } catch (TimeoutException e) {
  throw new IOException(&amp;quot;Failed to download due to timeout&amp;quot;);
 }
}  &lt;br&gt;&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      which would use handler defined above.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;7. Easy enough?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      I hope above shows that while doing incremental, &amp;quot;streaming&amp;quot; processing 
      is bit more work, it is not super difficult to do.
    &lt;/p&gt;
    &lt;p&gt;
      Not even when you have bit of pipelining to do, like uncompressing (or 
      compressing) data on the fly.
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/05-01-2012_05-31-2012.html#475</link>
<guid>http://www.cowtowncoder.com/blog/archives/05-01-2012_05-31-2012.html#475</guid>

<category>Java</category>

<category>Open Source</category>

<category>Performance</category>

<pubDate>Thu, 24 May 2012 17:26:05 -0700</pubDate>
</item>

<item>
<title>Jackson Data-binding: Did I mention it can do YAML as well?</title>
<description>&lt;p&gt;
      Note: as useful earlier articles, consider reading &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2012/03/entry_468.html&quot;&gt;Jackson 
      2.0: CSV-compatible as well&lt;/a&gt;&amp;quot; and &amp;quot;&lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2012/03/entry_467.html&quot;&gt;Jackson 
      2.0: now with XML, too!&lt;/a&gt;&amp;quot;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Inspiration&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Before jumping into the actual beef -- the new module -- I want to 
      mention my inspiration for this extension: the Greatest New Thing to hit 
      Java World Since JAX-RS called &lt;a href=&quot;https://github.com/codahale/dropwizard&quot;&gt;DropWizard&lt;/a&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      For those who have not yet tried it out and are unaware of its Kung-Fu 
      Panda like Awesomeness, please go and check it out. You won't be 
      disappointed.
    &lt;/p&gt;
    &lt;p&gt;
      DropWizard is a sort of mini-framework that combines great Java 
      libraries (I may be biased, as it does use Jackson), starting with 
      trusty JAX-RS/Jetty8 combination, building with Jackson for JSON, jDBI 
      for DB/JDBC/SQL, Java Validation API (impl from Hibernate project) for 
      data validation, and logback for logging; adding bit of Jersey-client 
      for client-building and optional FreeMarker plug-in for UI, all bundled 
      up in a nice, modular and easily understandable packet.&lt;br&gt;Most 
      importantly, it &amp;quot;Just Works&amp;quot; and comes with intuitive configuration and 
      bootstrapping system. It also builds easily into a single deployable jar 
      file that contains all the code you need, with just a bit of Maven 
      setup; all of which is well documented. Oh, and the documentation is 
      very accessible, accurate and up-to-date. All in all, a very rare 
      combination of things -- and something that would give RoR and other 
      &amp;quot;easier than Java&amp;quot; frameworks good run for their money, if hipsters ever 
      decided to check out the best that Java has to offer.
    &lt;/p&gt;
    &lt;p&gt;
      The most relevant part here is the configuration system. Configuration 
      can use either basic JSON or full YAML. And as I &lt;a href=&quot;http://www.cowtowncoder.com/blog/archives/2012/04/entry_473.html&quot;&gt;mentioned 
      earlier&lt;/a&gt;, I am beginning to appreciate YAML for configuring things.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1.1. The Specific inspirational nugget: YAML converter&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      The way DropWizard uses YAML is to parse it using SnakeYAML library, 
      then convert resulting document into JSON tree and then using Jackson 
      for data binding. This is useful since it allows one to use full power 
      of Jackson configuration including annotations and polymorphic type 
      handling.
    &lt;/p&gt;
    &lt;p&gt;
      But this got me thinking -- given that the whole converter 
      implementation about dozen lines or so (to work to degree needed for 
      configs), wouldn't it make sense to add &amp;quot;full support&amp;quot; for YAML into 
      Jackson family of plug-ins?
    &lt;/p&gt;
    &lt;p&gt;
      I thought it would.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. And Then There Was One More Backend for Jackson&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Turns out that implementation was, indeed, quite easy. I was able to 
      improve certain things -- for example, module can use lower level API to 
      keep performance bit better; and output side also works, not just reader 
      -- but in a way, there isn't all that much to do since all module has to 
      do is to convert YAML events into JSON events, and maybe help with some 
      conversions.
    &lt;/p&gt;
    &lt;p&gt;
      Some of more advanced things include:
    &lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;
        Format auto-detection works, thanks to &amp;quot;---&amp;quot; document prefix (that 
        generator also produces by default)
      &lt;/li&gt;
      &lt;li&gt;
        Although YAML itself exposes all scalars as text (unless type hints 
        are enabled, which adds more noise in content), module uses heuristics 
        to make parser implementation bit more natural; so although 
        data-binding can also coerce types, this should usually not be needed
      &lt;/li&gt;
      &lt;li&gt;
        Configuration includes settings to change output style, to allow use 
        of more aesthetically pleasing output (for those who prefer &amp;quot;wiki 
        look&amp;quot;, for example)
      &lt;/li&gt;
    &lt;/ul&gt;
    &lt;p&gt;
      At this point, functionality has been tested with a broad if shallow set 
      of unit tests; but because data-binding used is 100% same as with JSON, 
      testing is actually sufficient to use module for some work.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Usage? So boring I tell you&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Oh. And you might be interested in knowing how to use the module. This 
      is the boring part, since.... there isn't really much to it.
    &lt;/p&gt;
    &lt;p&gt;
      You just use &amp;quot;YAMLFactory&amp;quot; wherever you would normally use 
      &amp;quot;JsonFactory&amp;quot;; and then under the hood you get &amp;quot;YAMLParser&amp;quot; and 
      &amp;quot;YAMLGenerator&amp;quot; instances, instead of JSON equivalents. And then you 
      either use parser/generator directly, or, more commonly, construct an 
      &amp;quot;ObjectMapper&amp;quot; with &amp;quot;YAMLFactory&amp;quot; like so (code snippet itself is from 
      test &amp;quot;SimpleParseTest.java&amp;quot;)
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;  ObjectMapper mapper = new ObjectMapper(new YAMLFactory());&lt;br&gt;  User user = mapper.readValue(&amp;quot;firstName: Billy\n&amp;quot;&lt;br&gt;    +&amp;quot;lastName: Baggins\n&amp;quot;&lt;br&gt;    +&amp;quot;gender: MALE\n&amp;quot;&lt;br&gt;    +&amp;quot;userImage: AQIDBAY=&amp;quot;,&lt;br&gt;   User.class);&lt;/pre&gt;
    &lt;p&gt;
      &lt;hr&gt;
      and to get the functionality itself, Maven dependency is:&lt;hr&gt;
    &lt;/p&gt;
    &lt;pre&gt;&amp;lt;dependency&amp;gt;
  &amp;lt;groupId&amp;gt;com.fasterxml.jackson.dataformat&amp;lt;/groupId&amp;gt;
  &amp;lt;artifactId&amp;gt;jackson-dataformat-yaml&amp;lt;/artifactId&amp;gt;
  &amp;lt;version&amp;gt;2.0.0&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      &lt;b&gt;4. That's all Folks -- until you give us some Feedback!&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      That's it for now. I hope some of you will try out this new backend, and 
      help us further make Jackson 2.0 the &amp;quot;Universal Java Data Processor&amp;quot;
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/05-01-2012_05-31-2012.html#474</link>
<guid>http://www.cowtowncoder.com/blog/archives/05-01-2012_05-31-2012.html#474</guid>

<category>Java</category>

<category>JSON</category>

<category>Open Source</category>

<pubDate>Thu, 03 May 2012 22:12:03 -0700</pubDate>
</item>

<item>
<title>What me like YAML? (Confessions of a JSON advocate)</title>
<description>&lt;p&gt;
      Ok. I have to admit that I learnt something new and gained bit more 
      respect for YAML data format recently, when working on the 
      proof-of-concept for YAML-on-Jackson (&lt;a href=&quot;https://github.com/FasterXML/jackson-dataformat-yaml&quot;&gt;jackson-dataformat-yaml&lt;/a&gt;; 
      more on this on yet another Jackson 2.0 article, soon).&lt;br&gt;And since it 
      would be intellectually dishonest not to mention that my formerly 
      negative view on YAML has brightened up a notch, here's my write-up on 
      this bit of enlightenment.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Bad First Impressions Stick&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      My first look at YAML via its definition basically made my stomach turn. 
      It just looked so much like a bad American Ice Cream: &amp;quot;Too Much of 
      Everything&amp;quot; -- hey, if it isn't enough to have chocolate, banana and 
      walnut, let's throw in bit of caramel, root beer essence and touch of 
      balsamic vinegar; along with bit of organic arugula to spice things 
      up!&amp;quot;. That isn't the official motto, I thought, but might as well be. If 
      there is an O'Reilly book on YAML it surely must have platypus as the 
      cover animal.
    &lt;/p&gt;
    &lt;p&gt;
      That was my thinking up until few weeks ago.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Tale of the Two Goals&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      I have read most of YAML specification (which is not badly written at 
      all) multiple times, as well as shorter descriptions. My overall 
      conclusion has always been that there are multiple high-level design 
      decisions that I disagree with, and that these can mostly be summarized 
      that it tries to do too many things, tries to solve multiple conflicting 
      use cases.
    &lt;/p&gt;
    &lt;p&gt;
      But recently when working on adding YAML support as Jackson module 
      (based on nice &lt;a href=&quot;http://code.google.com/p/snakeyaml/&quot;&gt;SnakeYAML&lt;/a&gt; 
      library, solid piece of code, very unlike most parsers/generators I have 
      seen), I realized that fundamentally there are just two conflicting 
      goals:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        Define a Wiki-style markup for data (assuming it is easier to not only 
        write prose in, but also data)
      &lt;/li&gt;
      &lt;li&gt;
        Create a straight-forward Object serialization data format
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      (it is worth noting that these goals are orthogonal, functionality-wise; 
      but they conflict at level of syntax, visual appearance and complicate 
      handling significantly, mostly because there is always &amp;quot;more than one 
      way to do it&amp;quot; (Perl motto!))
    &lt;/p&gt;
    &lt;p&gt;
      I still think that one could solve the problem better by defining two, 
      not one, format: first one with a Wiki dialect; and second one with a 
      clean data format.&lt;br&gt;But this lead me to think about something: what if 
      those weird Wiki-style aspects were removed from YAML? Would I still 
      dislike the format?
    &lt;/p&gt;
    &lt;p&gt;
      And I came to conclusion that no, I would not dislike it. In fact, I 
      might like it. A lot.
    &lt;/p&gt;
    &lt;p&gt;
      Why? Let's see which things I like in YAML; things that JSON does not 
      have, but really really should have in the ideal world.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Things that YAML has and JSON should have&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Here's the quick rundown:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        Comments: oh lord, what kind of textual data format does NOT have 
        comments? JSON is the only one I know of; and even it had them before 
        spec was finalized. I can only imagine a brain fart of colossal 
        proportions caused it to be removed from the spec...
      &lt;/li&gt;
      &lt;li&gt;
        (optional) Document start and end markers (&amp;quot;---&amp;quot; header, &amp;quot;...&amp;quot; 
        footer&amp;quot;). This is such a nice thing to have; both for format 
        auto-detection purpose as well as for framing for data feeds. It's bit 
        of a no-brainer; but suspiciously, JSON has nothing of sort (XML does 
        have XML declaration which _almost_ works well, but not quite; but I 
        digress)
      &lt;/li&gt;
      &lt;li&gt;
        Type tags for type metadata: in YAML, one can add optional type tags, 
        to further indicate type of an Object (or any value actually). This is 
        such an essential thing to have; and with JSON one must use in-band 
        constructs that can conflict with data. XML at least has attributes 
        (&amp;quot;xsi:type&amp;quot;).
      &lt;/li&gt;
      &lt;li&gt;
        Aliases/anchors for Object Identity (aka &amp;quot;id / idref&amp;quot;): although data 
        is data, not objects with identity, having means to optionally pass 
        identity information is very, very useful. And here too XML has some 
        support (having attributes for metadata is convenient); and JSON has 
        nada.
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      The common theme with above is that all extra information is optional; 
      but if used, it is included discreetly and can be used as appropriate by 
      encoders, decoders, with or without using language- or platform-specific 
      resolution mechanisms.&lt;br&gt;And I think YAML actually declares these 
      things pretty well: it is neither over nor under engineered with respect 
      to these features. This is surprisingly delicate balance, and very well 
      chosen. I have seen over-complicated data formats (at Amazon, for 
      example) that didn't know where to stop; and we can see how JSON stopped 
      too short of even most rudimentary things (... comments). Interestingly, 
      XML almost sort-of has these features; but they come about with extra 
      constructs (xsi:type via XML Schema), or are side effects of otherwise 
      quirky features (element/attribute separation).
    &lt;/p&gt;
    &lt;p&gt;
      Having had to implement equivalent functionality on top of simplistic 
      JSON construct (&amp;quot;add yet another meta-property, in-line with actual 
      data; allow a way to configure it to reduce conflicts&amp;quot;), I envy having 
      these constructs as first-level concepts, convenient little additions 
      that allow proper separation of data and metadata (type, object id; 
      comments).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. Uses for YAML&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Still, having solved/worked around all of above problems -- Jackson 1.5 
      added full support for polymorphic types (&amp;quot;type tags&amp;quot;); 2.0 finally 
      added Object Identity (&amp;quot;alias/anchor&amp;quot;), use of linefeeds for framing can 
      substitute for document boundaries -- I do not have compelling case for 
      using YAML for data transfer. It's almost a pity -- I have come to 
      realize that YAML could have been a great data format (it is also old 
      enough to have challenged popularity of JSON, both seem to have been 
      conceived at about same time). As is, it is almost one.
    &lt;/p&gt;
    &lt;p&gt;
      Somewhat ironically, then, is that maybe Wiki features are acceptable 
      for the other main use case: that of configuration files. This is the 
      use case I have for YAML; and the main reason for writing compatibility 
      module (inspired by libs/frameworks like &lt;a href=&quot;https://github.com/codahale/dropwizard&quot;&gt;DropWizard&lt;/a&gt; 
      which use YAML as the main config file format).
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#473</link>
<guid>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#473</guid>

<category>JSON</category>

<pubDate>Tue, 10 Apr 2012 21:52:56 -0700</pubDate>
</item>

<item>
<title>Data format auto-detection with Jackson (JSON, XML, Smile, YAML)</title>
<description>&lt;p&gt;
      There is one fairly advanced feature of Jackson that has been around a 
      while (since version 1.8), but that has not really been publicized a 
      lot: data format auto-detection. Let's see how it works, and what it 
      could be used for.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Format detection?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      By format detection I mean ability to figure out most likely data format 
      that a piece of content has. Auto-detection means that a piece of code 
      can try to automatically deduce this, given set of data formats to 
      recognize, and accessor to content.
    &lt;/p&gt;
    &lt;p&gt;
      Jackson 1.8 added such capability to Jackson, by adding one new method 
      in JsonFactory abstract class:
    &lt;/p&gt;
    &lt;pre&gt;  public MatchStrength hasFormat(InputAccessor acc)&lt;/pre&gt;
    &lt;p&gt;
      as well as couple of supporting classes; and most importantly, a helper 
      class:
    &lt;/p&gt;
    &lt;pre&gt;  com.fasterxml.jackson.core.format.DataFormatDetector&lt;/pre&gt;
    &lt;p&gt;
      that coordinates calls to produce somewhat convenience mini-API for 
      format auto-detection.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. Show Me Some Code!&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Let's start with a simple demonstration, with known content that should 
      be either JSON or XML:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;  JsonFactory jsonF = new JsonFactory();&lt;br&gt;  XmlFactory xmlF = new XmlFactory(); // from com.fasterxml.jackson.dataformat.xml (jackson-dataformat-xml)&lt;br&gt;  // note: ordering is importtant; first one that gives full match is chosen:&lt;br&gt;  DataFormatDetector det = new DataFormatDetector(new JsonFactory[] { jsonF, xmlF });&lt;br&gt;  // let's accept about any match; but only if no &amp;quot;solid match&amp;quot; found
  det = det.withMinimalMatch(MatchStrength.WEAK_MATCH).withOptimalMatch(MatchStrength.SOLID_MATCH);&lt;br&gt;  // then see what we get:&lt;br&gt;  DataFormatMatcher match = det.findFormat(&amp;quot;{ \&amp;quot;name\&amp;quot; : \&amp;quot;Bob\&amp;quot; }&amp;quot;.getBytes(&amp;quot;UTF-8&amp;quot;));
  assertEquals(jsonF.getFormatName(), match.getMatchedFormatName());&lt;br&gt;  match = det.findFormat(&amp;quot;&amp;lt;?xml version='1.0'?&amp;gt;&amp;lt;root/&amp;gt;&amp;quot;.getBytes(&amp;quot;UTF-8&amp;quot;));&lt;br&gt;  assertEquals(xmlF.getFormatName(), match.getMatchedFormatName();&lt;br&gt;  // or:&lt;br&gt;  match = det.findForm(&amp;quot;neither really...&amp;quot;.getBytes(&amp;quot;UTF-8&amp;quot;));&lt;br&gt;  assertNull(match);&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      which is useful if we want to display information; but perhaps even more 
      useful, we can conveniently process the data.&lt;br&gt;So let's assume we have 
      file &amp;quot;data&amp;quot;, with format of either XML or JSON:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;  // note: can pass either byte[] or InputStream
  match = det.findFormat(new File(&amp;quot;data&amp;quot;));&lt;br&gt;  JsonParser p = match.createParserWithMatch();&lt;br&gt;  // or; if we wanted to get factory: JsonFactory matchedFactory = p.getMatch();&lt;br&gt;  ObjectMapper mapper = new ObjectMapper();&lt;br&gt;  User user = mapper.readValue(p, User.class);&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      Basically you can let &lt;i&gt;DataFormatMatcher&lt;/i&gt; construct a parser for 
      the matched type (note: some data formats require specific kind of 
      ObjectMapper to be used).
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Works on... ?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Basically, any format for which there is JsonFactory that properly 
      implements method &amp;quot;hasFormat()&amp;quot; can be auto-detected.
    &lt;/p&gt;
    &lt;p&gt;
      Currently (Jackson 2.0.0) this includes following data formats:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        JSON -- can detect standards-compliant data (main-level JSON Object or 
        Array); and to some degree other variants (scalar values at root-level)
      &lt;/li&gt;
      &lt;li&gt;
        Smile -- reliably detected, especially when the standard header is 
        written (enabled by default)
      &lt;/li&gt;
      &lt;li&gt;
        XML -- reliably detected either from XML declaration, or from first 
        tag, PI or comment
      &lt;/li&gt;
      &lt;li&gt;
        YAML: experimental &lt;a href=&quot;https://github.com/FasterXML/jackson-dataformat-yaml&quot;&gt;Jackson 
        YAML module&lt;/a&gt; can detect document start marker (&amp;quot;---&amp;quot;) for reliable 
        detection; otherwise inconclusive
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      One existing dataformat for which auto-detection does not yet work is 
      CSV: this is mostly due to inherent lack of header of any kind. However, 
      some heuristic support will likely be added soon.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. Most useful for? &lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      This feature was originally implemented to allow for automatic detection 
      and parsing of content that would be in either JSON, or a binary JSON 
      (Smile) representation. For this use case, things work reliably and 
      efficiently.
    &lt;/p&gt;
    &lt;p&gt;
      But fortunately system was designed to be pluggable, so it should 
      actually work for a variety of other cases. Ideally this should nicely 
      complement &amp;quot;universal data adapter&amp;quot; goal of Jackson project; so that you 
      could usually simply just feed a data file, and as long as it is in one 
      of supported formats, things would Just Work.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. Caveats&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Some things to note:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        Order of factories used for constructing &lt;i&gt;DataFormatDetector&lt;/i&gt; 
        matters: first one that provides optimal match is taken; and if no 
        optimal match is found, first of otherwise equal acceptable matches is 
        given
      &lt;/li&gt;
      &lt;li&gt;
        Some data formats require specific ObjectMapper implementation 
        (sub-class) to be used: for those formats, automatic parser creation 
        needs to be coupled with choosing of the right mapper (this may be 
        improved in future)
      &lt;/li&gt;
    &lt;/ol&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#472</link>
<guid>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#472</guid>

<category>Java</category>

<pubDate>Mon, 09 Apr 2012 19:19:46 -0700</pubDate>
</item>

<item>
<title>Java Type Erasure not a Total Loss -- use Java Classmate for resolving generic signatures</title>
<description>&lt;p&gt;
      As I have written before (&amp;quot;&lt;a href=&quot;/blog/archives/2010/12/entry_436.html&quot;&gt;Why 
      'java.lang.reflect.Type' Just Does Not Cut It&lt;/a&gt;&amp;quot;), Java's Type Erasure 
      can be a royal PITA.
    &lt;/p&gt;
    &lt;p&gt;
      But things are actually not quite as bleak as one might think. But let's 
      start with an actual somewhat unsolvable problem; and then proceed with 
      another important, similar, yet solvable problem.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;1. Actual Unsolvable problem: Java.util Collections&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Here is piece of code that illustrates a problem that most Java 
      developers either understand, or think they understand:
    &lt;/p&gt;
    &lt;pre&gt;  List&amp;lt;String,Integer&amp;gt; stringsToInts = new ArrayList&amp;lt;String,Integer&amp;gt;();&lt;br&gt;  List&amp;lt;byte[],Boolean&amp;gt; bytesToBools = new ArrayList&amp;lt;byte[], Boolean&amp;gt;();&lt;br&gt;  assertSame(stringsToInts.getclass(), bytesToBools.getClass();&lt;/pre&gt;
    &lt;p&gt;
      The problem is that although conceptually two collections seem to act 
      different, at source code level, they are instances of the very same 
      class (Java does not generate new classes for genericized types, unlike 
      C++).
    &lt;/p&gt;
    &lt;p&gt;
      So while compiler helps in keeping typing straight, there is little 
      runtime help to either enforce this, or allow other code to deduce 
      expected type; there just isn't any difference from type perspective.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;2. All Lost? Not at all&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      But let's look at another example. Starting with a simple interface
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;public interface Callable&amp;lt;IN, OUT&amp;gt; {&lt;br&gt;  public OUT call(IN argument);&lt;br&gt;}&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      do you think following is true also?
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;public void compare(Callable&amp;lt;?,?&amp;gt; callable1, Callable&amp;lt;?,?&amp;gt; callable2) {&lt;br&gt;  assertSame(callable1.getClass(), callable2.getClass());&lt;br&gt;}&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      Nope. Not necessarilly; classes may well be different. WTH?
    &lt;/p&gt;
    &lt;p&gt;
      The difference here is that since Callable is an interface (and you can 
      not instantiate an interface), instances must be of some other type; and 
      there is a good chance they are different.
    &lt;/p&gt;
    &lt;p&gt;
      But more importantly, if you use &lt;a href=&quot;https://github.com/cowtowncoder/java-classmate&quot;&gt;Java 
      ClassMate&lt;/a&gt; library (more on this in just a bit), we can even figure 
      out parameterization (unlike with earlier example, where all you could 
      see is that parameters are &amp;quot;a subtype of java.lang.Object&amp;quot;), so for 
      example we can do
    &lt;/p&gt;
    &lt;div&gt;
      &lt;hr&gt;
      // Assume 'callable1' was of type:
    &lt;/div&gt;
    &lt;div&gt;
      // class MyStringToIntList implements Callable&amp;lt;String, List&amp;lt;Integer&amp;gt;&amp;gt; { 
      ... }
    &lt;/div&gt;
    &lt;pre&gt;  TypeResolver resolver = new TypeResolver();
  ResolvedType type = resolver.resolve(callable1.getClass());
  List&amp;lt;ResolvedType&amp;gt; params = type.typeParametersFor(Callable.class);&lt;br&gt;  // so we know it has 2 parameters; from above, 'String' and 'List&amp;lt;Integer&amp;gt;'&lt;br&gt;  assertEquals(2, params.size());
  assertSame(String.class, params.get(0).getErasedType();&lt;br&gt;  // and second type is generic itself; in this case can directly access&lt;br&gt;  ResolvedType resultType = params.get(1);&lt;br&gt;  assertSame(List.class, resultType.getErasedType());&lt;br&gt;  List&amp;lt;ResolvedType&amp;gt; listParams = resultType.getTypeParameters();&lt;br&gt;  assertSame(Integer.class, listParams.get(0).getErasedType();&lt;br&gt;  //or, just to see types visually, try:&lt;br&gt;  String desc = type.getSignature(); // or 'getFullDescription'&lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      How is THIS possible? (fun exercise: pick 5 of your favorite Java 
      experts; ask if above is possible, observe how most of them would have 
      said &amp;quot;nope, not a chance&amp;quot; :-) )
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;3. Long live generics -- hidden deep, deep within&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Basically generic type information is actually stored in class 
      definitions, in 3 places:
    &lt;/p&gt;
    &lt;ol&gt;
      &lt;li&gt;
        When defining parent type information (&amp;quot;super type&amp;quot;); parameterization 
        for base class and base interface(s) if any
      &lt;/li&gt;
      &lt;li&gt;
        For generic field declarations
      &lt;/li&gt;
      &lt;li&gt;
        For generic method declarations (return, parameter and exception types)
      &lt;/li&gt;
    &lt;/ol&gt;
    &lt;p&gt;
      It is the first place where ClassMate finds its stuff. When resolving a 
      Class, it will traverse the inheritance hierarchy, recomposing type 
      parameterizations. This is a rather involved process, mostly due to type 
      aliasing, ability for interfaces to use different signatures and so on. 
      In fact, trying to do this manually first looks feasible, but if you try 
      it via all wildcarding, you will soon realize why having a library do it 
      for you is a nice thing...
    &lt;/p&gt;
    &lt;p&gt;
      So the important thing to learn is this: &lt;i&gt;&lt;b&gt;to retain run-time 
      generic type information, you MUST pass concrete sub-types which resolve 
      generic types via inheritance&lt;/b&gt;&lt;/i&gt;.
    &lt;/p&gt;
    &lt;p&gt;
      And this is where JDK collection types bring in the problem (wrt this 
      particular issue): concerete types like ArrayList still take generic 
      parameters; and this is why runtime instances do not have generic type 
      available.
    &lt;/p&gt;
    &lt;p&gt;
      Another way to put this is that when using a subtype, say:
    &lt;/p&gt;
    &lt;hr&gt;
    

    &lt;pre&gt;  MyStringList list = new ArrayList&amp;lt;String&amp;gt;() { }&lt;br&gt;  // can use ClassMate now, a la:&lt;br&gt;  ResolvedType type = resolver.resolve(list.getClass());&lt;br&gt;  // type itself has no parameterization (concrete non-generic class); but it does implement List so:
  List&amp;lt;ResolvedType&amp;gt; params = type.typeParametersFor(List.class);&lt;br&gt;  assertSame(String.class, params.get(0).getErasedType());  &lt;/pre&gt;
    &lt;hr&gt;
    

    &lt;p&gt;
      which once again would retain usable amount of generic type information.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;4. Real world usage?&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Above might seem as an academic exercise; but it is not. When designing 
      typed APIs, many callbacks would actually benefit from proper generic 
      typing. And of special interest are callbacks or handlers that need to 
      do type conversions.
    &lt;/p&gt;
    &lt;p&gt;
      As an example, my favorite Database access library, jDBI, makes use of 
      this functionality (using embedded ClassMate) to figure out data-binding 
      information without requiring extra Class argument. That is, you could 
      pass something like (not an actual code sample):
    &lt;/p&gt;
    &lt;pre&gt;  MyPojo value = dbThingamabob.query(queryString, handler);&lt;/pre&gt;
    &lt;p&gt;
      instead of what would more commonly requested:
    &lt;/p&gt;
    &lt;pre&gt;  MyPojo value = dbThingamabob.query(queryString, handler, MyPojo.class);&lt;/pre&gt;
    &lt;p&gt;
      and framework could still figure out what kind of thing 'handler' would 
      handle, assuming it was a generic interface caller has to implement.
    &lt;/p&gt;
    &lt;p&gt;
      difference may seem minute, but this can actually help a lot by 
      simplifying some aspects of type passing, and remove one particular mode 
      of error.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;5. More on ClassMate&lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      Above actually barely scratch surface of what &lt;a href=&quot;https://github.com/cowtowncoder/java-classmate&quot;&gt;ClassMate&lt;/a&gt; 
      provides. Although it is already tricky to find &amp;quot;simple&amp;quot; 
      parameterization for main-level classes, there are much more trickier 
      things. Specifically, resolving types of Fields and Methods (return 
      types, parameters). Given classes like:
    &lt;/p&gt;
    &lt;pre&gt;  public interface Base&amp;lt;T&amp;gt; {
    public T getStuff();
  }
  public class ListBase&amp;lt;T&amp;gt; implements Base&amp;lt;List&amp;lt;T&amp;gt;&amp;gt; {&lt;br&gt;    protected T value;&lt;br&gt;    protected ListBase(T v) { value = v; }&lt;br&gt;    public T getstuff() { return value; }&lt;br&gt;  }
  public class Actual implements ListBase&amp;lt;String&amp;gt; {&lt;br&gt;    public Actual(List&amp;lt;String&amp;gt; value) { super(value; }&lt;br&gt;  }&lt;/pre&gt;
    &lt;p&gt;
      you might be interested in figuring out, exactly what is the type of 
      return value of &amp;quot;getStuff()&amp;quot;. By eyeballing, you know it should be 
      &amp;quot;List&amp;lt;String&amp;gt;&amp;quot;, but bytecode does not tell this -- in fact, it just 
      tells it's &amp;quot;T&amp;quot;, basically.
    &lt;/p&gt;
    &lt;p&gt;
      But with ClassMate you can resolve it:
    &lt;/p&gt;
    &lt;pre&gt;  // start with ResolvedType; need MemberResolver
  ResolvedType classType = resolver.resolve(Actual.class);&lt;br&gt;  MemberResolver mr = new MemberResolver(resolver);&lt;br&gt;  ResolvedTypeWithMembers beanDesc = mr.resolve(classType, null, null);&lt;br&gt;  ResolvedMethod[] members = bean.getMemberMethods();&lt;br&gt;  ResolvedType returnType = null;&lt;br&gt;  for (ResolvedMethod m : members) {&lt;br&gt;    if (&amp;quot;getStuff&amp;quot;.equals(m.getName())) {&lt;br&gt;      returnType = m.getReturnType();&lt;br&gt;    }&lt;br&gt;  }&lt;br&gt;  // so, we should get&lt;br&gt;  assertSame(List.class, returnType.getErasedType());&lt;br&gt;  ResolvedType elemType = returnType.getTypeParameters().get(0);&lt;br&gt;  assertSame(String.class, elemType.getErasedType();&lt;br&gt;&lt;/pre&gt;
    &lt;p&gt;
      and get the information you need.
    &lt;/p&gt;
    &lt;p&gt;
      &lt;b&gt;6. Why so complicated for nested types? &lt;/b&gt;
    &lt;/p&gt;
    &lt;p&gt;
      One thing that is obvious from code samples is that code that uses 
      ClassMate is not as simple as one might hope. Handling of nested generic 
      types, specifically, is bit verbose in some cases (specifically: when 
      type we are resolving does not directly implement type we are interested 
      in)&lt;br&gt;Why is that?
    &lt;/p&gt;
    &lt;p&gt;
      The reason is that there is a wide variety of interfaces that any class 
      can (and often does) implement. Further, parameterizations may vary at 
      different levels, due to co-variance (ability to override methods with 
      more refined return types). This means that it is not practical to &amp;quot;just 
      resolve it all&amp;quot; -- and even if this was done, it is not in general 
      obvious what the &amp;quot;main type&amp;quot; would be. For these reasons, you need to 
      manually request parameterization for specific generic classes and 
      interfaces as you traverse type hierarchy: there is no other way to do 
      it.
    &lt;/p&gt;</description>
<link>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#471</link>
<guid>http://www.cowtowncoder.com/blog/archives/04-01-2012_04-30-2012.html#471</guid>

<category>Java</category>

<category>Open Source</category>

<pubDate>Sat, 07 Apr 2012 13:51:28 -0700</pubDate>
</item>

</channel>
</rss>
